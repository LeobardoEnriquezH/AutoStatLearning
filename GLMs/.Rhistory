MinAIC=which.min(unlist(AICList))
ModMinAIC=ModelList[[MinAIC]]
#summary(ModMinAIC)
#Mostrar los AIC, BIC, modelo y liga
ModMinAIC$family
AICList[[MinAIC]]
BICList[[MinAIC]]
FormList[[MinAIC]]
#El modelo con menor AIC
MinAIC=which.min(unlist(AICList))
ModMinAIC=ModelList[[MinAIC]]
summary(ModMinAIC)
knitr::opts_chunk$set(echo = T, fig.width = 6, fig.height = 3.5)
#rm(list = ls())
pacman::p_load(tidyverse,
kableExtra,
cowplot,
stargazer,knitr,viridis,dplyr,readr,scales,quantmod,texreg,tinytex,
tidyr, imager,lubridate,tseries, astsa, growthrates, tis, dynlm,
readxl, foreign, hrbthemes, gtsummary, corrplot, lm.beta, ggfortify,
AER, lmtest, sandwich,GGally, ggplot2, multcomp, purrr, VGAM, lessR,
flextable, performance, see,qqplotr, ggrepel, patchwork,boot,rempsyc,
report, ggResidpanel,DHARMa, SuppDists)
datos<-read_csv("Preg1B.csv", show_col_types = FALSE)
datos$sex<-factor(datos$sex) #declaramos la variable como factor
#Realizamos un relevel para poner como referencia "1" hombre
datos$sex<-relevel(datos$sex,"1")
modelo1<-lm(data=datos, bpsystol ~ bmi + sex + age)
#summary(modelo1)
table_tests<-nice_assumptions(modelo1) #usamos esta función de biblioteca rempsyc
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#AIC Usando la función performance_aicc de biblioteca performance
modelo2 <- lm(log(bpsystol) ~  bmi + factor(sex) + age, datos)
#summary(modelo2)
AICY<-performance_aic(modelo2)
#Modelo 2 con logaritmos
modelo2=lm(data=datos, I(log(bpsystol)) ~ bmi + sex + age)
#summary(modelo2)
#stargazer(modelo1, modelo2)
par(mfrow = c(2, 2))
##check_model() function of performance package
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo2, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[6]]
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
###check_model function of performance package: p-values ###
#check_collinearity(modelo1) # VIF
#check_autocorrelation(modelo1) #  Autocorrelated residuals p value
#check_heteroscedasticity(modelo1) # non-constant error variance (heteroscedasticity): p value
#check_outliers(modelo1) # Outliers method and threshold: cook
# check_normality(modelo1) # Normality of residuals p value
# nice_assumptions() function of  rempsyc package
table_tests2<-nice_assumptions(modelo2)
table_tests_fin2<-subset(table_tests2, select = -c(Model,Diagnostic) )
# Table
kable(t(table_tests_fin2)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Las AIC no son comparables directamente por la transformación hecha
#AICmodelo1<-AIC(modelo1)
#AICmodelo2<-AIC(modelo2)
#La primera prueba que se debe realizar es
#prueba asociada a la tabla ANOVA de regresión lineal múltiple
library(multcomp)
K=matrix(c(0,1,0,0), ncol=4, nrow=1)
m=0
prueba_dir<-glht(modelo2, linfct=K, rhs=m, alternative ="greater")
summary(prueba_dir)
# Se rechaza H0, lo que implica que se puede proceder al análisis del modelo
curva_ajustada_mujer30 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x +
modelo2$coefficients[3] + modelo2$coefficients[4]*30)}
curva_ajustada_hombre30 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x  +
modelo2$coefficients[4]*30)}
curva_ajustada_mujer50 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x +
modelo2$coefficients[3] + modelo2$coefficients[4]*50)}
curva_ajustada_hombre50 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x  +
modelo2$coefficients[4]*50)}
curva_ajustada_mujer64 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x +
modelo2$coefficients[3] + modelo2$coefficients[4]*64)}
curva_ajustada_hombre64 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x  +
modelo2$coefficients[4]*64)}
ggplot(datos, aes(bmi, bpsystol)) +
geom_point() +
geom_function(fun = curva_ajustada_mujer30, aes(linetype = "mujer de 30") ,col="red", lwd = 1)+
geom_function(fun = curva_ajustada_hombre30, aes(linetype = "hombre de 30") ,col="green", lwd = 1)+
geom_function(fun = curva_ajustada_mujer50, aes(linetype = "mujer de 50") ,col="red", lwd = 0.8) +
geom_function(fun = curva_ajustada_hombre50, aes(linetype = "hombre de 50") ,col="green", lwd = 0.8)+
geom_function(fun = curva_ajustada_mujer64, aes(linetype = "mujer de 64") ,col="red", lwd = 0.5) +
geom_function(fun = curva_ajustada_hombre64, aes(linetype = "hombre de 64") ,col="green", lwd = 0.5)+
theme_bw()
datos<-read_csv("Preg1B.csv", show_col_types = FALSE)
datos$sex<-factor(datos$sex) #declaramos la variable como factor
#Realizamos un relevel para poner como referencia "1" hombre
datos$sex<-relevel(datos$sex,"1")
#Seleccionar un modelo entre un conjunto de posibles glm, mediante mallas
#Comp lineal: a)transf BoxTidwell(potencias) a x y b) polinomio sobre x
#Mallas para el valor de potencia y grado de polinomio:
malla=seq(from = 1, to = 5, by = 1)
Poli <- cbind("poly", malla)
malla=seq(from = -3, to = 3, by = .5)
Pot <- cbind("pot", malla)
CompLin=rbind(Poli, Pot)
#Componente aleatorio: Y es continua y positiva, tenemos tres opciones:
#Malla con distribucion Normal, Gausiana e Inversa Gausiana
Distribuciones=c("gaussian", "Gamma", "inverse.gaussian")
#Funcion liga:inverse, identity, log, y 1/mu^2(solo para IG)
FunLigas=c("identity", "log", "inverse", "1/mu^2")
#Declaramos longitud o dimensión de los vectores
nFunLigas=length(FunLigas)
nDist=length(Distribuciones)
nCompLin=dim(CompLin)[1]
#Creación de variables para guardar resultados
ModelList=list(NA)  #guardar resultados del ajuste, objeto glm
AICList=list(NA)    #guardar el AIC del modelo
BICList=list(NA)    #guardar el BIC del modelo
FormList=list(NA)   #guardar la formula usada para el ajuste
#Modelos 18*2*3+18*1*4(tres funciones ligas para 2 distrib y 4 para una, IG)
#Generamos los cíclos y combinaciones de las mallas
index=0
for(k in 1:nCompLin){
#definimos componente lineal y formula
if(CompLin[k,1]=="poly"){
formstring=paste0("bpsystol ~ age+sex+poly(bmi,",  CompLin[k,2], ", raw=TRUE)")
}else{
if(CompLin[k,2]==0){
formstring=paste0("bpsystol ~ age+sex+I(log(bmi))")}else
{
formstring=paste0("bpsystol ~ age+sex+I(bmi^(",  CompLin[k,2], "))")}
}
form <- as.formula(formstring)
for(j in 1:nDist){
for(l in 1:nFunLigas){
#definicion del argumento family
if(FunLigas[l]=="1/mu^2"){
if(Distribuciones[j]=="inverse.gaussian"){
index=index+1
Dist=get(Distribuciones[j])  #obtener la funcion a usar
Mod.A.Prueba=glm(form, data=datos, family = Dist(link=FunLigas[l]))
ModelList[[index]]=Mod.A.Prueba
AICList[[index]]=AIC(Mod.A.Prueba)
BICList[[index]]=BIC(Mod.A.Prueba)
FormList[[index]]=formstring
}
}else{
index=index+1
Dist=get(Distribuciones[j])
Mod.A.Prueba=glm(form, data=datos, family = Dist(link=FunLigas[l]))
ModelList[[index]]=Mod.A.Prueba
AICList[[index]]=AIC(Mod.A.Prueba)
BICList[[index]]=BIC(Mod.A.Prueba)
FormList[[index]]=formstring
}
}
}
}
#El modelo con menor AIC
MinAIC=which.min(unlist(AICList))
ModMinAIC=ModelList[[MinAIC]]
summary(ModMinAIC)
#Mostrar los AIC, BIC, modelo y liga
ModMinAIC$family
AICList[[MinAIC]]
BICList[[MinAIC]]
FormList[[MinAIC]]
modelo_glm1<-glm(formula = bpsystol ~ age+sex+bmi, family = inverse.gaussian(link = identity), data = datos)
summary(modelo_glm1)
#stargazer(ModMinAIC, modelo_glm1)
K=matrix(c(0,1,0,0,
0,0,1,0,
0,0,0,1), ncol=4, nrow=3, byrow=TRUE)
m=c(0,0,0)
summary(glht(modelo_glm1, linfct=K, rhs=m), test=Chisqtest())
# Se incluye cierta aleatorización para datos binarios
library(statmod)
fitlogitqr <- qresid(modelo_glm1)
#qqnorm( fitlogitqr, las=1 ); qqline( fitlogitqr)
lilKS<-nortest::lillie.test(fitlogitqr)
Shapiro<-shapiro.test(fitlogitqr)
resid_panel(modelo_glm1, plots=c("all"),scale = 1)
set.seed(123)
fit2res <- simulateResiduals(fittedModel = modelo_glm1)
plot(fit2res)
K=matrix(c(0,0,0,1), ncol=4, nrow=1, byrow=TRUE)
m=0
prueba<-glht(modelo_glm1, linfct=K, rhs=m, alternative="greater")
#summary(prueba)
curva_ajustada_mujer30 <- function(x) {modelo_glm1$coefficients[1] + modelo_glm1$coefficients[4]*x + modelo_glm1$coefficients[3] + modelo_glm1$coefficients[2]*30}
curva_ajustada_hombre30 <- function(x) {modelo_glm1$coefficients[1] + modelo_glm1$coefficients[4]*x  + modelo_glm1$coefficients[2]*30}
curva_ajustada_mujer50 <- function(x) {modelo_glm1$coefficients[1] + modelo_glm1$coefficients[4]*x + modelo_glm1$coefficients[3] + modelo_glm1$coefficients[2]*50}
curva_ajustada_hombre50 <- function(x) {modelo_glm1$coefficients[1] + modelo_glm1$coefficients[4]*x  + modelo_glm1$coefficients[2]*50}
curva_ajustada_mujer64 <- function(x) {modelo_glm1$coefficients[1] + modelo_glm1$coefficients[4]*x + modelo_glm1$coefficients[3] + modelo_glm1$coefficients[2]*64}
curva_ajustada_hombre64 <- function(x) {modelo_glm1$coefficients[1] + modelo_glm1$coefficients[4]*x  + modelo_glm1$coefficients[2]*64}
ggplot(datos, aes(bmi, bpsystol)) +
geom_point() +
geom_function(fun = curva_ajustada_mujer30, aes(linetype = "mujer de 30") ,col="red", lwd = 1) +
geom_function(fun = curva_ajustada_hombre30, aes(linetype = "hombre de 30") ,col="green", lwd = 1) +
geom_function(fun = curva_ajustada_mujer50, aes(linetype = "mujer de 50") ,col="red", lwd = 0.8) +
geom_function(fun = curva_ajustada_hombre50, aes(linetype = "hombre de 50") ,col="green", lwd = 0.8) +
geom_function(fun = curva_ajustada_mujer64, aes(linetype = "mujer de 64") ,col="red") +
geom_function(fun = curva_ajustada_hombre64, aes(linetype = "hombre de 64") ,col="green") + theme_bw()
#AIC Usando la función performance_aicc de biblioteca performance
modelo2 <- lm(log(bpsystol) ~  bmi + factor(sex) + age, datos)
#summary(modelo2)
AICY<-performance_aic(modelo2)
#Modelo Reg Lineal con logaritmos
modelo2=lm(data=datos, I(log(bpsystol)) ~ bmi + sex + age)
#summary(modelo2)
#summary(modelo_glm1)
#stargazer(modelo2, modelo_glm1)
datos<-read_csv("https://raw.githubusercontent.com/LeobardoEnriquezH/Data/main/Preg3B.csv", show_col_types = FALSE)
datos$Insecticide<-factor(datos$Insecticide) #declaramos la variable como factor
#Realizamos un relevel para poner como referencia "1"
datos$Insecticide<-relevel(datos$Insecticide,"A")
#Creamos dato de proporcion de insectos que mueren
datos$p_Killed<-datos$Killed/datos$Number
ggplot(data=datos, aes(x=Deposit,y=p_Killed, colour=Insecticide))+ geom_point()+ theme_bw()+
theme(text = element_text(size = 11),element_line(linewidth =0.5))
#Convertimos a datos desagrupados (más común en la práctica)
#library(tidyverse)
datos$NoKilled<-datos$Number-datos$Killed
datna_1=datos %>% group_by(Killed,Insecticide,Deposit) %>%
do( data.frame(died= rep(1, .$Killed)))
datna_2=datos %>% group_by(Killed,Insecticide,Deposit) %>%
do( data.frame(died= rep(0, .$NoKilled)))
datna<-rbind(datna_1,datna_2)
#Generar variables con datos en logaritmos
datna$lnD=log(datna$Deposit)
#datos$lnD=factor(datos$lnD) #declaramos la variable como factor
#En general hay 4 ligas que se podrían usar para covariables factores: logit, probit, cloglog y log.
#Aqui emplearemos 3 ligas porque tenemos una variable numérica entre las covariables, omitimos liga log.
fitlogit=glm(died~Insecticide*lnD, family = binomial(link="logit"), data=datna)
#summary(fitlogit)
fitprob=glm(died~Insecticide*lnD, family = binomial(link="probit"), data=datna)
#summary(fitprob)
fitcll=glm(died~Insecticide*lnD, family = binomial(link="cloglog"), data=datna)
#summary(fitcll)
#En general hay 4 ligas que se podrían usar para covariables factores: logit, probit, cloglog y log.
#Aqui emplearemos 3 ligas porque tenemos una variable numérica entre las covariables, omitimos liga log.
fitlogit_s=glm(died~Insecticide+lnD, family = binomial(link="logit"), data=datna)
#summary(fitlogit)
fitprob_s=glm(died~Insecticide+lnD, family = binomial(link="probit"), data=datna)
#summary(fitprob)
fitcll_s=glm(died~Insecticide+lnD, family = binomial(link="cloglog"), data=datna)
#summary(fitcll)
#stargazer(fitlogit, fitprob, fitcll, fitlogit_s, fitprob_s, fitcll_s)
#A continuación se muestran los valores AIC y BIC, respectivamente, para las ligas logit, probit y cloglog.
#Se elige el modelo con el menor AIC, que es el de la liga probit.
#Además con el modelo completo también los criterios AIC y BIC coinciden
# ("AIC:logit probit cloglog")
# c(AIC(fitlogit), AIC(fitprob),  AIC(fitcll))
# ("BIC:logit probit cloglog")
# c(BIC(fitlogit), BIC(fitprob), BIC(fitcll))
#La primera prueba que se debe realizar es
#la similar a la prueba asociada a la tabla ANOVA en regresión lineal múltiple
library(multcomp)
K=matrix(c(0,1,0,0,
0,0,1,0,
0,0,0,1), ncol=4, nrow=3, byrow=TRUE)
m=c(0,0,0)
summary(glht(fitprob_s, linfct=K, rhs=m), test=Chisqtest())  #Chisqtest() es apropiada para datos donde y no es continua
# Se rechaza H0, lo que implica que se puede proceder
# al análisis del modelo
datna$lnD2=datna$lnD*datna$lnD
#En general hay 4 ligas que se podrían usar para covariables factores: logit, probit, cloglog y log.
#Aqui emplearemos 3 ligas porque tenemos una variable numérica entre las covariables, omitimos liga log.
fitlogit=glm(died~Insecticide*lnD+Insecticide*lnD2, family = binomial(link="logit"), data=datna)
#summary(fitlogit)
fitprob=glm(died~Insecticide*lnD+Insecticide*lnD2, family = binomial(link="probit"), data=datna)
#summary(fitprob)
fitcll=glm(died~Insecticide*lnD+Insecticide*lnD2, family = binomial(link="cloglog"), data=datna)
#summary(fitcll)
#En general hay 4 ligas que se podrían usar para covariables factores: logit, probit, cloglog y log.
#Aqui emplearemos 3 ligas porque tenemos una variable numérica entre las covariables, omitimos liga log.
fitlogit_s=glm(died~Insecticide+lnD +lnD2, family = binomial(link="logit"), data=datna)
#summary(fitlogit)
fitprob_s=glm(died~Insecticide+lnD +lnD2, family = binomial(link="probit"), data=datna)
#summary(fitprob)
fitcll_s=glm(died~Insecticide+lnD +lnD2, family = binomial(link="cloglog"), data=datna)
#summary(fitcll)
#stargazer(fitlogit, fitprob, fitcll, fitlogit_s, fitprob_s, fitcll_s)
#Además con el modelo completo también los criterios AIC y BIC coinciden
# ("AIC:logit probit cloglog")
# c(AIC(fitlogit), AIC(fitprob),  AIC(fitcll))
# ("BIC:logit probit cloglog")
# c(BIC(fitlogit), BIC(fitprob), BIC(fitcll))
#La primera prueba que se debe realizar es
#la similar a la prueba asociada a la tabla ANOVA en regresión lineal múltiple
library(multcomp)
K=matrix(c(0,1,0,0,0,
0,0,1,0,0,
0,0,0,1,0,
0,0,0,0,1), ncol=5, nrow=4, byrow=TRUE)
m=c(0,0,0,0)
summary(glht(fitprob_s, linfct=K, rhs=m), test=Chisqtest())  #Chisqtest() es apropiada para datos donde y no es continua
# Se rechaza H0, lo que implica que se puede proceder
# al análisis del modelo
# Se incluye cierta aleatorización para datos binarios
library(statmod)
fitlogitqr <- qresid(fitprob_s)
#qqnorm( fitlogitqr, las=1 ); qqline( fitlogitqr)
lilKS<-nortest::lillie.test(fitlogitqr)
Shapiro<-shapiro.test(fitlogitqr)
library(DHARMa)  #Los residuales simulados también son útiles en este caso
set.seed(123)
fitprobitres <- simulateResiduals(fittedModel = fitprob_s)
plot(fitprobitres)
deviance_df<-deviance(fitprob_s)/df.residual(fitprob_s)
newdata <- data.frame(Insecticide = c("A", "A","A","A", "A","A","B","B", "B", "B","B", "B","C","C", "C", "C","C", "C"), lnD = c(0.6931472, 0.9707789, 1.2470323,1.5238800, 1.8017098, 2.0794415, 0.6931472, 0.9707789, 1.2470323,1.5238800, 1.8017098, 2.0794415, 0.6931472, 0.9707789, 1.2470323,1.5238800, 1.8017098, 2.0794415), lnD2 = c(0.4804530, 0.9424117, 1.5550895,2.32221, 3.246158, 4.32407, 0.4804530, 0.9424117, 1.5550895,2.32221, 3.246158, 4.32407, 0.4804530, 0.9424117, 1.5550895,2.32221, 3.246158, 4.32407) )
newdata$prob_s <- predict(fitprob_s, newdata[,1:3], type = c("response"), se.fit=TRUE)$fit
newdata$Deposit<-exp(newdata$lnD)
kable(newdata)
newdata1<- newdata[,-c(1,5)]
datosfin<-cbind(datos,newdata1)
ggplot(data=datos, aes(x=Deposit,y=p_Killed, colour=Insecticide))+ geom_point() +theme_bw()+
geom_line(data=datosfin, aes(x=Deposit,y=prob_s, colour=Insecticide))+theme_bw()
#Resolver función cuadrática
quad <- function(a, b, c)
{
a <- as.complex(a)
answer <- c((-b + sqrt(b^2 - 4 * a * c)) / (2 * a),
(-b - sqrt(b^2 - 4 * a * c)) / (2 * a))
if(all(Im(answer) == 0)) answer <- Re(answer)
if(answer[1] == answer[2]) return(answer[1])
answer
}
#Para insecticida A
a=fitprob_s$coefficients[5]
b=fitprob_s$coefficients[4]
c=fitprob_s$coefficients[1]-qnorm(.7)
D_A<-exp(quad(a, b, c))
#Para insecticida B
a=fitprob_s$coefficients[5]
b=fitprob_s$coefficients[4]
c=fitprob_s$coefficients[1]+fitprob_s$coefficients[2]-qnorm(.7)
D_B<-exp(quad(a, b, c))
#Para insecticida C
a=fitprob_s$coefficients[5]
b=fitprob_s$coefficients[4]
c=fitprob_s$coefficients[1]+fitprob_s$coefficients[3]-qnorm(.7)
D_C<-exp(quad(a, b, c))
library(multcomp)
K=matrix(c(0,0,1,0,0,
0,-1,1,0,0), ncol=5, nrow=2, byrow=TRUE)
m=c(0,0)
summary(glht(fitprob_s, linfct=K, rhs=m, alternative="greater"), test=Chisqtest())
library(multcomp)
K=matrix(c(0,1,0,0,0), ncol=5, nrow=1, byrow=TRUE)
m=c(0)
summary(glht(fitprob_s, linfct=K, rhs=m), test=Chisqtest())
data4 <- read_csv("Preg4.csv")
#Primero haremos factor las variables de ciudad y edad
data4$City <- as.factor(data4$City)
#Tambien crearemos la variable que indicara la tasa de incidencia
data4$incidencia <- data4$Cases/data4$Pop
ggplot(data=data4, aes(x=Age,y=incidencia, colour=City))+ geom_point()+ theme_classic()+
theme(text = element_text(size = 11),element_line(linewidth =0.5))
#Lo que nos interesa es ver si es estudiar si se puede indicar que a mayor edad existe mayor incidencia de cancer de pulmon
# Notar que para dejar en terminos de la variable con conteos,
# al considerar la liga log se debe incluir log(data4$Pop) [offset]
#### log(mu_y/t)=b0+b1x
####    log(mu_y)=log(t)+b0+b1x
data4$logPop=log(data4$Pop)
ajuste1 <- glm(Cases ~ offset(logPop)+ Age * City , family=poisson(link="log"), data=data4)
summary(ajuste1)
# Regla de dedo para analizar si hay un problema por
# considerar el parametro de dispersion igual a 1
dev_res1<-deviance(ajuste1)/df.residual(ajuste1)
ajuste2 <- glm(Cases ~ offset(logPop) + Age , family=poisson(link="log"), data=data4)
summary(ajuste2)
#stargazer(ajuste1, ajuste2)
#Regla de dedo para analizar si hay un problema por
# considerar el parametro de dispersion igual a 1
dev_res<-deviance(ajuste2)/df.residual(ajuste2)
library(DHARMa)
set.seed(1234)
fitres_2 <- simulateResiduals(fittedModel = ajuste2)
plot(fitres_2)
anova(ajuste1,ajuste2, test = "Chisq")
library(MASS)
fit_negbin3 <- glm.nb(Cases ~ offset(logPop)+ Age , data = data4, link = "log")
summary(fit_negbin3)
#stargazer(fit_negbin3)
#Verifiquemos los supuestos de este modelo con DHARMa
#En este caso nuevamente omitiremos los resultados de las pruebas de los supuestos para este modelo ya que no se usara debido a que se escogio como mejor ajuste el modelo anterior
set.seed(123)
fit_neg <- simulateResiduals(fittedModel = fit_negbin3)
plot(fit_neg)
#Podemos decir que este tambien parece ser buen modelo, al menos es mucho mejor #que el primero, sin embargo no parece ser mejor que el segundo modelo.
#Comparemos los AIC y BIC de los ultimos 2 modelos para ver cual es mejor en este #aspecto.
("AIC:(2), AIC:(3)")
c(AIC(ajuste2), AIC(fit_negbin3))
("BIC:(2), BIC:(3)")
c(BIC(ajuste2), BIC(fit_negbin3))
#Para los intervalos de confianza lo que haremos sera definir una malla de valores para la edad.
library(MASS)
Edad <- seq(from = 40, to =74, by = .5)
#el calculo de los intervalos los haremos a una confianza del 95%
#E(y;x)= b0 + b1 incidencia^1.8  + b2 Age
library(multcomp)
K_1 <- cbind(0,0,0,1,Edad)
#banda del primer grupo de edad
fittI <- glht(ajuste2, linfct = K_1)
fitci3 <- confint(fittI, level = 0.95)
plot(Edad, coef(fittI), col="black", type="l", main="Incidencia de Cáncer por Edad")+
lines(Edad, fitci3$confint[,"upr"], col="red")+
lines(Edad, fitci3$confint[,"lwr"], col="red")+
abline(h=110, col="blue")
#Aplicando la funcion inversa para obtener los valores sobre la esperanza de y, omitiremos este resultado, sin embargo es de utilidad para saber en que nivel nos permite obtener estimaciones directas de la media esperada de la variable de respuesta en el espacio original de la variable de respuesta, lo que facilita su interpretación y comparación con otros datos o modelos. Esto es especialmente útil cuando estamos interesados en las predicciones en la escala original de la variable de respuesta, en lugar de en la escala del predictor lineal.
#exp(fitci3$confint)
Datos<-read_csv("Preg5.csv", show_col_types = FALSE)
Datos[sapply(Datos, is.character)] <- lapply(Datos[sapply(Datos, is.character)], as.factor)
Datos$TypeInflCont=factor(paste(Datos$Type, Datos$Infl, Datos$Cont, sep="."))
v.Type.Infl.Cont=(Datos$TypeInflCont)
v.Sat=Datos$Sat
BarChart(x=v.Type.Infl.Cont , by=v.Sat, stack100=TRUE, srt=0, horiz=TRUE)
#Primero ajustamos un modelo de Satisfacción (Sat) con todas las interacciones posibles
#Entre influencia sobre mantenimiento, tipo de vivienda y contacto con otros vecinos (Infl, Type y Cont)
fit_comp <- vglm(Sat ~ Infl*Type*Cont, #Fórmula
family = multinomial(refLevel = "Low"), #Familia
data = Datos) #Datos
#Funciona de forma equivalente a los glm
#Posteriormente un modelo que no contenga ninguna interacción
fit_no_int <- vglm(Sat ~ Infl+Type+Cont,
family = multinomial(refLevel = "Low"),
data = Datos)
#summary(fit_comp)
#coef(fit_comp, matrix = TRUE) # Le indicamos que nos los muestre como matriz
#summary(fit_no_int)
#coef(fit_no_int, matrix = TRUE) # Le indicamos que nos los muestre como matriz
#Escribimos los dos modelos y la salida es la prueba
anova(fit_no_int, fit_comp, test="LRT", type = "I")
AIC_fit_comp<-AIC(fit_comp)
AIC_fit_no_int<-AIC(fit_no_int)
summary(fit_no_int)
Datos$Sat=factor(Datos$Sat, ordered=TRUE, levels = c("Low", "Medium", "High"))
#Ajustamos utilizando de nuevo la función vglm: modelo de probabilidades NO proporcionales
fit_ord_nopar <- vglm(Sat ~ Infl+Type+Cont,
family = cumulative(parallel = FALSE), #La diferencia es esta
data = Datos)
#El orden viene de que respuesta es tipo factor y a esta le pusimos orden
#Ajustamos utilizando de nuevo la función vglm: modelo de probabilidades proporcionales
fit_ord_par <- vglm(Sat ~ Infl+Type+Cont,
family = cumulative(parallel = TRUE), #La diferencia es esta
data = Datos)
coef(fit_ord_nopar, matrix=TRUE)
summary(fit_ord_par)
coef(fit_ord_par, matrix=TRUE)
#Comparamos los modelos
anova(fit_ord_par, fit_ord_nopar, type = "I")
AIC_fit_ord_par<-AIC(fit_ord_par)
AIC_fit_ord_no_par<-AIC(fit_ord_nopar)
summary(fit_ord_par)
#Agruparemos los datos desagrupados
Datos$SatTypeInflCont=factor(paste(Datos$Sat, Datos$TypeInflCont, sep="."))
by_SatTypeInflCont <- Datos %>% group_by(SatTypeInflCont)
by_SatTypeInflCont<-by_SatTypeInflCont %>% tally()
Dat <- data.frame(do.call('rbind', strsplit(as.character(by_SatTypeInflCont$SatTypeInflCont),'.',fixed=TRUE)))
names(Dat) <- c("Sat", "Type", "Infl", "Cont")
Dat$SatTypeInflCont<-factor(paste(Dat$Sat, Dat$Type, Dat$Infl, Dat$Cont,sep="."))
DatosAg<-merge(Dat, by_SatTypeInflCont, by = "SatTypeInflCont", all = TRUE)
#Obtenemos las combinaciones, aprovechando la tabla agregada
combinaciones <- unique(DatosAg[,3:5]) %>%
arrange(Type, Infl, Cont)
#También podríamos obtenerla con los datos desagregados como:
#combinaciones <- unique(datos[,1:2]) %>% arrange(Sexo, Edad)
#Con esto aplicamos la función predict, con tipo "response" y tenemos:
probas <- predict(fit_ord_par, combinaciones, type = "response")
#Finalmente, unimos las combinaciones con sus probabilidafes
datos_modelo <- data.frame(cbind(combinaciones, probas))
#Obtenemos las combinaciones, con la tabla agregada
DatosAg_Apartment<-DatosAg%>%filter(Type %in% "Apartment") #Filtramos apartment
combinaciones <- unique(DatosAg_Apartment[,3:5]) %>%
arrange(Type, Infl, Cont)
#También podríamos obtenerla con los datos desagregados como:
#combinaciones <- unique(datos[,1:2]) %>% arrange(Sexo, Edad)
#Con esto aplicamos la función predict, con tipo "response" y tenemos:
probas <- predict(fit_ord_par, combinaciones, type = "response")
#Finalmente, unimos las combinaciones con sus probabilidafes
datos_modelo <- data.frame(cbind(combinaciones, probas))
#Le cambiamos el nombre, para más adelante (en caso de que no aparezcan los nombres)
colnames(datos_modelo)<-c("Type", "Infl", "Cont", "Low", "Medium", "High")
#En este caso, necesitamos los datos en tipo long
data_long <- datos_modelo %>%
pivot_longer(cols = c(`Low`, Medium, `High`),
names_to = "Sat",
values_to = "Probabilidad") %>%
#Aplicamos orden al tipo factor
mutate("Respuesta"=factor(Sat, levels = c("Low", "Medium", "High")), "Infl"=factor(Infl, levels = c("Low", "Medium", "High")), "Cont"=factor(Cont, levels = c("Low",  "High")))
#Con esto podemos crear la gráfica
ggplot(data_long, aes(x = Infl, y = Probabilidad, fill = Sat)) +
geom_bar(stat = "identity", position = position_dodge(width = 0.8),
width = 0.7) +
geom_text(aes(label = round(Probabilidad, 2)),
position = position_dodge(width = 0.8),
vjust = -0.7, size = 3) +  # Añadir etiquetas con probabilidades
facet_grid(. ~ Cont) + #Este nos permite separar por Cont
labs(
title = "Probabilidades de Satisfacción (Sat) por Contacto (Cont) e Influencia (Infl)",
x = "Influencia (Infl) en mantenimiento del Apartment",
y = "Probabilidad"
) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "top"
) + theme_bw()
