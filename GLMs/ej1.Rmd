---
title: ""
author: ""
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, include=FALSE}
library(tidyverse)
library(stargazer)
library(kableExtra)
library(flextable)
library(performance)
library(see)
library(lmtest)
library(qqplotr)
library(ggrepel)
library(patchwork)
library(boot)
library(rempsyc)
library(report)
```

## 1. Regresión lineal múltiple.


### i) Modelo de RLM reducido para E(bpsystol; bmi, sex, age) con datos originales. 

Para analizar si existe una asociación entre la presión arterial sistólica (bpsystol) como variable dependiente y el índice de masa corporal (bmi), ajustaremos un modelo de regresión lineal múltiple, considerando el sexo (sex: 1-hombre y 2-mujer con nivel de referencia hombre) y la edad (age) de los pacientes. Para ello usaremos la base de datos ``reg1B.csv`` con 295 pacientes, 142 hombres y 153 mujeres, de entre 20 y 74 años. En el cuadro de MODELOS se muestran los resultados del Modelo 1 planteado, sin pretratamiento de los datos. 

La prueba global $F$ muestra un p-value menor a 0.05, por lo que rechazamos la hipótesis nula de que los parámetros estimados son cero, es decir, podemos decir que al menos un coeficiente estimado es distinto de cero, por lo que el modelo es estadísticamente significativo al nivel de confianza del 95%. Las pruebas individuales también rechazan la hipótesis nula con la preba $t-student$, es decir, todos los coeficientes son significativos al 5%, pues se rechaza la hipótesis nula de que en lo individual sean iguales a cero. 



```{r, echo=FALSE}
datos<-read_csv("Preg1B.csv", show_col_types = FALSE)
datos$sex<-factor(datos$sex) #declaramos la variable como factor
#Realizamos un relevel para poner como referencia "1" hombre
datos$sex<-relevel(datos$sex,"1")
```


```{r, echo=FALSE}
modelo1<-lm(data=datos, bpsystol ~ bmi + sex + age)
#summary(modelo1)
```






En el siguiente Cuadro se pueden observar las pruebas de Shapiro-Wilk, Breusch-Pagan y Durbin-Watson para el Modelo 1, que plantean la hipótesis nulas de normalidad, homoscedasticidad y no autocorrelación, respectivamente. Se concluye que el Modelo 1 presenta no autocorrelación y homoscedasticidad, sin embargo no presenta normalidad de los errores. Por lo que tendremos que hacer algunos ajustes al modelo, con algunos tratamientos a las variables. 


```{r, echo=FALSE}
table_tests<-nice_assumptions(modelo1)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )

kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
```




### ii) Modelo adecuado con transformación de datos.




Como tenemos un problema con la normalidad, procederemos a hacer primero una transformación a la variable dependiente, probaremos con una transformación más usual que es la logarítmica, la cual se puede interpretar más fácilmente.  Por simplicidad no consideraremos en el Modelo 2 interacciones entre las variables y se propone una transformación Box Cox logarítimica de la variable dependiente. Para este Modelo 2, se observa en el Cuadro de MODELOS que la prueba global $F$ rechaza la hipótesis nula, por lo que al menos un coeficiente estimado es distinto de cero, y las pruebas $t-student$ individuales de los coeficientes estimados también rechazan las hipótesis nulas analizados individualmente. Notemos que *** implica que se rechaza la hipótesis nula incluso con un nivel de confianza del 99%, el p-value es menor a 0.01.   



```{r, echo=FALSE}
#Modelo 2 con logaritmos
modelo2=lm(data=datos, I(log(bpsystol)) ~ bmi + sex + age)
#summary(modelo2)
```




```{r, echo=FALSE}
#stargazer(modelo1, modelo2)
```


\begin{table}[!htbp] \centering 
  \caption{MODELOS} 
  \label{} 
\footnotesize
\begin{tabular}{@{\extracolsep{5pt}}lcc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{2}{c}{\textit{Dependent variable:}} \\ 
\cline{2-3} 
\\[-1.8ex] & bpsystol & I(log(bpsystol)) \\ 
\\[-1.8ex] & (1) & (2)\\ 
\hline \\[-1.8ex] 
 bmi & 1.208$^{***}$ & 0.009$^{***}$ \\ 
  & (0.202) & (0.002) \\ 
  & & \\ 
 sex2 & $-$5.664$^{***}$ & $-$0.049$^{***}$ \\ 
  & (1.964) & (0.015) \\ 
  & & \\ 
 age & 0.484$^{***}$ & 0.004$^{***}$ \\ 
  & (0.059) & (0.0004) \\ 
  & & \\ 
 Constant & 78.496$^{***}$ & 4.461$^{***}$ \\ 
  & (5.510) & (0.042) \\ 
  & & \\ 
\hline \\[-1.8ex] 
Observations & 295 & 295 \\ 
R$^{2}$ & 0.310 & 0.321 \\ 
Adjusted R$^{2}$ & 0.302 & 0.314 \\ 
Residual Std. Error (df = 291) & 16.784 & 0.127 \\ 
F Statistic (df = 3; 291) & 43.497$^{***}$ & 45.922$^{***}$ \\ 
AIC:  & $2507.213$ & $-376.2099$ \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 





Para poder tener una interpretación válida de los coeficientes, veremos que el Modelo 2 cumple con los supuestos del modelo de regresión lineal. Primero se mostrarán algunas gráficas. La Gráfica **Residuals vs Fitted Values**, se utiliza para comprobar los supuestos de relación lineal, una línea horizontal, sin patrones distintos, es indicación de una relación lineal, lo que es bueno en nuestro caso. La Gráfica **Sample Q Deviation vs Standard Normal Distribution Q**, se utiliza para examinar si los residuos se distribuyen normalmente, es bueno que los puntos residuales sigan la línea recta, en nuestro caso parece que todo se ajusta bien, pues tenemos muchos valores que siguen la linea. La Gráfica **Scale-Location: Sqrt(|Std. Residuals|) vs Fitted values**, se utiliza para comprobar la homogeneidad de la varianza de los residuos (homoscedasticidad), la línea horizontal con puntos igualmente distribuidos es una buena indicación de homocedasticidad, este es el caso en nuestro modelo, donde no tenemos un problema de heterocedasticidad. La Gráfica **Std. Residuals vs Leverage**, se utiliza para identificar casos de valores influyentes, es decir, valores extremos que podrían influir en los resultados de la regresión cuando se incluyen o excluyen del análisis, al parecer ningún valor sale de la distancia de Cook.  






```{r, echo=FALSE, warning=FALSE,  message=FALSE, fig.width = 6, fig.height = 2.8}
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####

# return a list of single plots
diagnostic_plots <- plot(check_model(modelo2, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[6]]
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]


```






```{r, echo=FALSE}
###check_model function of performance package: p-values ###

#check_collinearity(modelo1) # VIF
#check_autocorrelation(modelo1) #  Autocorrelated residuals p value
#check_heteroscedasticity(modelo1) # non-constant error variance (heteroscedasticity): p value
#check_outliers(modelo1) # Outliers method and threshold: cook
# check_normality(modelo1) # Normality of residuals p value
```





En el siguiente Cuadro, se muestra las pruebas de Shapiro-Wilk, Breusch-Pagan y Durbin-Watson para el Modelo 2, que plantean la hipótesis nulas de normalidad, homoscedasticidad y no autocorrelación, respectivamente. En todos los casos no hay evidencia suficiente para rechazar las hipótesis nulas. 


```{r, echo=FALSE}
# nice_assumptions() function of  rempsyc package: table
table_tests2<-nice_assumptions(modelo2)
table_tests_fin2<-subset(table_tests2, select = -c(Model,Diagnostic) )

kable(t(table_tests_fin2)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
```




```{r, echo=FALSE}
#Las AIC no son comparables directamente por la transformación hecha
#AICmodelo1<-AIC(modelo1)
#AICmodelo2<-AIC(modelo2)

```





### iii) Asociación entre masa corporal y presión arterial sistólica.


Se puede concluir que para una persona de cierta edad y sexo, tener un índice de masa corporal alto se asocia con una alta presión arterial sistólica. Tomando en cuanta en el Cuadro anterior que se rechaza la hipótesis nula $H_0:\beta_1=0$ contra la anternativa de que $H_a: \beta_1 \neq0$, a continuación se plantea la prueba de hipótesis con dirección, en donde la hipótesis nula es $H_0: \beta_1<0$ y la alternativa $H_a: \beta_1>0$. 


```{r, echo=FALSE, message=FALSE}
#La primera prueba que se debe realizar es 
#prueba asociada a la tabla ANOVA de regresión lineal múltiple

library(multcomp)
K=matrix(c(0,1,0,0), ncol=4, nrow=1)
m=0

prueba_dir<-glht(modelo2, linfct=K, rhs=m, alternative ="greater")
#summary(prueba_dir)

# Se rechaza H0, lo que implica que se puede proceder
# al análisis del modelo
```


El resultado de la prueba con dirección  ``Simultaneous Tests for General Linear Hypotheses`` con el ajuste $lm(formula = I(log(bpsystol)) \sim bmi + sex + age, data = datos)$ muestra un p-value de $1.2e-09$, lo cual rechaza la hipótesis nula planteada. Por lo tanto, para una persona de cierta edad y sexo, tener un índice de masa corporal alto se asocia con una alta presión arterial sistólica.   


### iv) Gráfica resumen con la estimación puntual de la relación bpsystol y bmi. 


A continuación presentaremos una gráfica resumen con la estimación puntual asociada a la relación entre bpsystol y bmi. Para esto consideremos sólo tres posibles edades: 30, 50 y 64, así como la diferenciación entre mujeres y hombres. El comportamiento en general es que los hombres tienden a tener una mayor presión arterial sistólica, comparado con las mujeres. En todos los casos al aumentar la masa corporal, la presión arterial sistólica incrementa tanto para hombres como para mujeres. Además podemos observar que a mayor edad, es mayor la presión arterial sistólica tanto para hombres como para mujeres. 


```{r, echo=FALSE}
curva_ajustada_mujer30 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x + modelo2$coefficients[3] + modelo2$coefficients[4]*30)}
curva_ajustada_hombre30 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x  + modelo2$coefficients[4]*30)}

curva_ajustada_mujer50 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x + modelo2$coefficients[3] + modelo2$coefficients[4]*50)}
curva_ajustada_hombre50 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x  + modelo2$coefficients[4]*50)}

curva_ajustada_mujer64 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x + modelo2$coefficients[3] + modelo2$coefficients[4]*64)}
curva_ajustada_hombre64 <- function(x) {exp(modelo2$coefficients[1] + modelo2$coefficients[2]*x  + modelo2$coefficients[4]*64)}

```



```{r, echo=FALSE, fig.width = 6, fig.height = 3}
ggplot(datos, aes(bmi, bpsystol)) +
  geom_point() +
  geom_function(fun = curva_ajustada_mujer30, aes(linetype = "mujer de 30") ,col="skyblue", lwd = 1) +
  geom_function(fun = curva_ajustada_hombre30, aes(linetype = "hombre de 30") ,col="green") +
  geom_function(fun = curva_ajustada_mujer50, aes(linetype = "mujer de 50") ,col="darkblue", lwd = 0.8) +
  geom_function(fun = curva_ajustada_hombre50, aes(linetype = "hombre de 50") ,col="darkgreen") +
  geom_function(fun = curva_ajustada_mujer64, aes(linetype = "mujer de 64") ,col="red") +
  geom_function(fun = curva_ajustada_hombre64, aes(linetype = "hombre de 64") ,col="magenta") + theme_bw()
```











