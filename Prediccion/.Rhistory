error = F)
library(mlbench)
library(GGally)
library(metrica)
library(MASS)
library(glmnet)
library(bestglm)
library(e1071)
library(data.table)
library(kableExtra)
library(ggplot2)
library(boot)
library (ISLR)
library(caret)
library(stargazer)
library(faraway)
library(tidyverse)
data<-faraway::fat
data<-subset(data, select = -c(siri, density, free) )
data<-filter(data, brozek>0)
View(data)
ggplot(data$weight) +
aes(x = "", y = hwy) +
geom_boxplot(fill = "steelblue") +
theme_minimal()
boxplot(data$weight)
boxplot(data$weight,
ylab = "hwy",
main = "Boxplot of highway miles per gallon"
)
mtext(paste("Outliers: ", paste(out, collapse = ", ")))
out <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "hwy",
main = "Boxplot of highway miles per gallon"
)
mtext(paste("Outliers: ", paste(out, collapse = ", ")))
out <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "hwy",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out, collapse = ", ")))
out <- boxplot.stats(data$height)$out
boxplot(data$height,
ylab = "hwy",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out, collapse = ", ")))
out_weight <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
out_height <- boxplot.stats(data$height)$out
boxplot(data$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
out_weight
data<-filter(data, weight!=363.15)
View(data)
data<-filter(data, weight!=363.15)
data<-filter(data, weight!=262.75)
out_height
data<-filter(data, weight!=363.15)
data<-filter(data, weight!=262.75)
data<-filter(data, height!=29.5)
out_weight <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
out_height <- boxplot.stats(data$height)$out
boxplot(data$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
data<-faraway::fat
out_weight <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
out_height <- boxplot.stats(data$height)$out
boxplot(data$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all.names = TRUE))
knitr::opts_chunk$set(
echo = FALSE,
fig.align = "center",
#fig.dim = c(6.0, 5.0),
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F)
library(mlbench)
library(GGally)
library(metrica)
library(MASS)
library(glmnet)
library(bestglm)
library(e1071)
library(data.table)
library(kableExtra)
library(ggplot2)
library(boot)
library (ISLR)
library(caret)
library(stargazer)
library(faraway)
library(tidyverse)
#Cargamos la base y quitamos siri, density y free, ademas quitamos ceros de brozek
data<-faraway::fat
data<-subset(data, select = -c(siri, density, free) )
data<-filter(data, brozek>0)
#Boxplot para ver los outliers para weight
out_weight <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
#Boxplot para ver los outliers para height
out_height <- boxplot.stats(data$height)$out
boxplot(data$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
#Quitamos los outliers
data<-filter(data, weight!=363.15)
data<-filter(data, weight!=262.75)
data<-filter(data, height!=29.5)
#Graficamos Boxplots para ver que ya no tenemos outliers
out_weight <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
out_height <- boxplot.stats(data$height)$out
boxplot(data$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
View(data)
# Datos a usar
library (ISLR)
help(Hitters)
Datos=Hitters
Datos = na.omit(Datos)
str(Datos)
View(Datos)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all.names = TRUE))
knitr::opts_chunk$set(
echo = FALSE,
fig.align = "center",
#fig.dim = c(6.0, 5.0),
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F)
library(mlbench)
library(GGally)
library(metrica)
library(MASS)
library(glmnet)
library(bestglm)
library(e1071)
library(data.table)
library(kableExtra)
library(ggplot2)
library(boot)
library (ISLR)
library(caret)
library(stargazer)
library(faraway)
library(tidyverse)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all.names = TRUE))
knitr::opts_chunk$set(
echo = FALSE,
fig.align = "center",
#fig.dim = c(6.0, 5.0),
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F)
library(mlbench)
library(GGally)
library(metrica)
library(MASS)
library(glmnet)
library(bestglm)
library(e1071)
library(data.table)
library(kableExtra)
library(ggplot2)
library(boot)
library (ISLR)
library(caret)
library(stargazer)
library(faraway)
library(tidyverse)
library(caret)
#Cargamos la base y quitamos siri, density y free, ademas quitamos ceros de brozek
data<-faraway::fat
data<-subset(data, select = -c(siri, density, free) )
data<-filter(data, brozek>0)
#Boxplot para ver los outliers para weight
out_weight <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
#Boxplot para ver los outliers para height
out_height <- boxplot.stats(data$height)$out
boxplot(data$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
#Quitamos los outliers
data<-filter(data, weight!=363.15)
data<-filter(data, weight!=262.75)
data<-filter(data, height!=29.5)
#Graficamos Boxplots para ver que ya no tenemos outliers
out_weight <- boxplot.stats(data$weight)$out
boxplot(data$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
out_height <- boxplot.stats(data$height)$out
boxplot(data$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
# Por simplicidad se usará:
# Repeated holdout method
# B=50, train (80%) y test (20%)
# y cálculo del MSE como medida de poder predictivo
# La partición se realizará con caret y
# será la misma para todos los modelos
library(caret)
set.seed(1)
B=50
Partition<- createDataPartition(data$brozek, p = .80, groups =4, list = FALSE, times = B)
#Primero modelo: efectos principales
# Descripción del método de entrenamiento y regla final
mod1=lm(brozek ~ ., data)
summary(mod1)  # regla final, la que se usaría en producción
#Primero modelo: efectos principales
# Descripción del método de entrenamiento y regla final
# Creamos la matriz de diseño X y la variable de respuesta y
X <- model.matrix(object = brozek ~ ., data = fat)
Y <- fat$brozek
mod1=lm(brozek ~ ., data)
summary(mod1)  # regla final, la que se usaría en producción
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all.names = TRUE))
knitr::opts_chunk$set(
echo = FALSE,
fig.align = "center",
#fig.dim = c(6.0, 5.0),
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F)
library(mlbench)
library(GGally)
library(metrica)
library(MASS)
library(glmnet)
library(bestglm)
library(e1071)
library(data.table)
library(kableExtra)
library(ggplot2)
library(boot)
library (ISLR)
library(caret)
library(stargazer)
library(faraway)
library(tidyverse)
library(caret)
#Cargamos la base y quitamos siri, density y free, ademas quitamos ceros de brozek
fat<-faraway::fat
fat<-subset(fat, select = -c(siri, density, free) )
fat<-filter(fat, brozek>0)
#Boxplot para ver los outliers para weight
out_weight <- boxplot.stats(fat$weight)$out
boxplot(fat$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
#Boxplot para ver los outliers para height
out_height <- boxplot.stats(fat$height)$out
boxplot(fat$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
#Quitamos los outliers
fat<-filter(fat, weight!=363.15)
fat<-filter(fat, weight!=262.75)
fat<-filter(fat, height!=29.5)
#Graficamos Boxplots para ver que ya no tenemos outliers
out_weight <- boxplot.stats(fat$weight)$out
boxplot(fat$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
out_height <- boxplot.stats(fat$height)$out
boxplot(fat$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
# Por simplicidad se usará:
# Repeated holdout method
# B=50, train (80%) y test (20%)
# y cálculo del MSE como medida de poder predictivo
# La partición se realizará con caret y
# será la misma para todos los modelos
library(caret)
set.seed(1)
B=50
Partition<- createDataPartition(fat$brozek, p = .80, groups =4, list = FALSE, times = B)
#Primero modelo: efectos principales
# Descripción del método de entrenamiento y regla final
# Creamos la matriz de diseño X y la variable de respuesta y
X <- model.matrix(object = brozek ~ ., data = fat)
Y <- fat$brozek
mod1=lm(brozek ~ ., fat)
summary(mod1)  # regla final, la que se usaría en producción
##
# Medición del poder predictivo de la regla final
mod1RHM=function(x, IndTrain, Dat){
train= IndTrain[,x]
test = (-train)
modtr=lm(Salary ~ ., Dat[train,])
predte=predict(modtr, Dat[test,])
MSE=mean((Dat$Salary[test]-predte)^2)
return(MSE)
}
MSE.B.mod1= sapply(1:B,mod1RHM, IndTrain=Partition, Dat=Datos)
##
# Medición del poder predictivo de la regla final
mod1RHM=function(x, IndTrain, Dat){
train= IndTrain[,x]
test = (-train)
modtr=lm(Salary ~ ., Dat[train,])
predte=predict(modtr, Dat[test,])
MSE=mean((Dat$Salary[test]-predte)^2)
return(MSE)
}
MSE.B.mod1= sapply(1:B,mod1RHM, IndTrain=Partition, Dat=fat)
##
# Medición del poder predictivo de la regla final
mod1RHM=function(x, IndTrain, Dat){
train= IndTrain[,x]
test = (-train)
modtr=lm(brozek ~ ., Dat[train,])
predte=predict(modtr, Dat[test,])
MSE=mean((Dat$Salary[test]-predte)^2)
return(MSE)
}
MSE.B.mod1= sapply(1:B,mod1RHM, IndTrain=Partition, Dat=fat)
(MSE.RHM.mod1=mean(MSE.B.mod1))
#[1] 118964.9
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all.names = TRUE))
knitr::opts_chunk$set(
echo = FALSE,
fig.align = "center",
#fig.dim = c(6.0, 5.0),
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F)
library(mlbench)
library(GGally)
library(metrica)
library(MASS)
library(glmnet)
library(bestglm)
library(e1071)
library(data.table)
library(kableExtra)
library(ggplot2)
library(boot)
library (ISLR)
library(caret)
library(stargazer)
library(faraway)
library(tidyverse)
library(caret)
#Cargamos la base y quitamos siri, density y free, ademas quitamos ceros de brozek
fat<-faraway::fat
fat<-subset(fat, select = -c(siri, density, free) )
fat<-filter(fat, brozek>0)
#Boxplot para ver los outliers para weight
out_weight <- boxplot.stats(fat$weight)$out
boxplot(fat$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
#Boxplot para ver los outliers para height
out_height <- boxplot.stats(fat$height)$out
boxplot(fat$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
#Quitamos los outliers
fat<-filter(fat, weight!=363.15)
fat<-filter(fat, weight!=262.75)
fat<-filter(fat, height!=29.5)
#Graficamos Boxplots para ver que ya no tenemos outliers
out_weight <- boxplot.stats(fat$weight)$out
boxplot(fat$weight,
ylab = "lbs",
main = "Weight"
)
mtext(paste("Outliers: ", paste(out_weight, collapse = ", ")))
out_height <- boxplot.stats(fat$height)$out
boxplot(fat$height,
ylab = "inches",
main = "Height"
)
mtext(paste("Outliers: ", paste(out_height, collapse = ", ")))
# Por simplicidad se usará:
# Repeated holdout method
# B=50, train (80%) y test (20%)
# y cálculo del MSE como medida de poder predictivo
# La partición se realizará con caret y
# será la misma para todos los modelos
library(caret)
set.seed(1)
B=50
Partition<- createDataPartition(fat$brozek, p = .80, groups =4, list = FALSE, times = B)
#Primero modelo: efectos principales
# Descripción del método de entrenamiento y regla final
# Creamos la matriz de diseño X y la variable de respuesta y
X <- model.matrix(object = brozek ~ ., data = fat)
Y <- fat$brozek
mod1=lm(brozek ~ ., fat)
summary(mod1)  # regla final, la que se usaría en producción
##
# Medición del poder predictivo de la regla final
mod1RHM=function(x, IndTrain, Dat){
train= IndTrain[,x]
test = (-train)
modtr=lm(brozek ~ ., Dat[train,])
predte=predict(modtr, Dat[test,])
MSE=mean((Dat$Salary[test]-predte)^2)
return(MSE)
}
MSE.B.mod1= sapply(1:B,mod1RHM, IndTrain=Partition, Dat=fat)
(MSE.RHM.mod1=mean(MSE.B.mod1))
#[1] 118964.9
rm(list = ls(all.names = TRUE))
gc()
# Datos a usar
library (ISLR)
help(Hitters)
Datos=Hitters
Datos = na.omit(Datos)
str(Datos)
# La partición se realizará con caret y
# será la misma para todos los modelos
library(caret)
set.seed(1)
B=50
Partition<- createDataPartition(Datos$Salary, p = .80, groups =4, list = FALSE, times = B)
##############################
### Primer modelo a explorar
### Sólo efectos principales
##############################
##
# Descripción del método de entrenamiento y regla final
mod1=lm(Salary ~ ., Datos)
summary(mod1)  # regla final, la que se usaría en producción
mod1RHM=function(x, IndTrain, Dat){
train= IndTrain[,x]
test = (-train)
modtr=lm(Salary ~ ., Dat[train,])
predte=predict(modtr, Dat[test,])
MSE=mean((Dat$Salary[test]-predte)^2)
return(MSE)
}
MSE.B.mod1= sapply(1:B,mod1RHM, IndTrain=Partition, Dat=Datos)
(MSE.RHM.mod1=mean(MSE.B.mod1))
