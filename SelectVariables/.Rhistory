error = F
)
datos3  <- read.csv("Dat3Ex.csv") #Variables continuas sin escalar
datos3 <- datos3[,c("V1", "V2", "V4", "V6", "V9", "V12","V14","V16","V17","V26",
"V27","V29","V31","V34","V37")] #seleccionamos las preguntas
names(datos3)=c("Parlanchin", "Victimista", "Deprimido", "Reservado", "Relajado",
"Peleonero", "Tenso", "Entusiasta",  "Indulgente", "Asertivo",
"Frio", "Malhumorado", "Timido", "Calmado", "Grosero")#renombramos
#colSums(is.na(datos3))#Verificar si las variables tienen Na's
#library(GGally)
#X11()
#ggpairs(datos3)#Ver las relaciones y si es necesario escalar
library(factoextra)
R.CP_org=prcomp(datos3,  scale = FALSE) #obtenemos las componentes principales sin sacale
R.CP_est=prcomp(datos3, scale = TRUE) #obtenemos las componentes principales con sacale
R.CP_log=prcomp(log10(datos3), scale = FALSE)#obtenemos las componentes principales con log
#Nos apoyamos con la varianza que recuperamos para decidir
print(summary(R.CP_org), digits=3) #en 4 se acumulan 62.6% y en 5 67.9%
print(summary(R.CP_est), digits=3) #en 4 se acumula 62.21% y en 5 67.48%
print(summary(R.CP_log), digits=3) #en 4 se acumula 63.92% y en 5 65.58%
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
#Ahora para interpretar, hay que sacar correlaciones entre comp principles
#y las variables originales
#A mayor/menor valor en el comp pricipal hay mas "variables"
options(digits=2)
cor(cbind(R.CP_org$x[,1:4],(datos3)))
cor(cbind(R.CP_est$x[,1:4], (scale(datos3))))
cor(cbind(R.CP_log$x[,1:4], (log(datos3))))
plot1<-fviz_pca_var(R.CP_org,labelsize = 3,repel = TRUE,
col.var = "contrib") + theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
plot2<-fviz_pca_var(R.CP_est,labelsize = 3,repel = TRUE,
col.var = "contrib") + theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
plot3<-fviz_pca_var(R.CP_log,labelsize = 3,repel = TRUE,
col.var= "contrib")+ theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
grid.arrange(plot1,  plot3,  ncol=2)
library(psych)
set.seed(123)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 4 factores
FE_org <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 4, rotate = "none")
FE_est <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 4, rotate = "none")
FE_log <- fa(log10(datos3), cor= "cov",
covar = TRUE, nfactor = 4, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
fa.diagram(FE_log,cut = 0.4 , main = "En logaritmos")
parallel <- fa.parallel((datos3), fa="fa", n.iter=100)
View(datos3)
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "promax")
FE_log <- fa(log10(datos3), cor= "cov",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
fa.diagram(FE_log,cut = 0.4 , main = "En logaritmos")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "promax")
FE_log <- fa(log10(datos3), cor= "cov",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
fa.diagram(FE_log,cut = 0.4 , main = "En logaritmos")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "promax")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
fa.diagram(FE_log,cut = 0.4 , main = "En logaritmos")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
fa.diagram(FE_log,cut = 0.4 , main = "En logaritmos")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "none")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
fa.diagram(FE_log,cut = 0.4 , main = "En logaritmos")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 4 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 4, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 4, rotate = "none")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 4, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
fa.diagram(FE_log,cut = 0.4 , main = "En logaritmos")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 4 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 4, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 4, rotate = "varimax")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 4, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
fa.diagram(FE_log,cut = 0.4 , main = "En logaritmos")
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 4 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "varimax")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "Promax")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "varimax")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
grid.arrange(plot4,  plot5,  ncol=2)
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
grid.arrange(plot4,  plot5,  ncol=2)
#Limpieza
rm(list = ls(all.names = TRUE)) #ambiente
gc()  #memoria
# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
echo = FALSE,
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F
)
datos3  <- read.csv("Dat3Ex.csv") #Variables continuas sin escalar
datos3 <- datos3[,c("V1", "V2", "V4", "V6", "V9", "V12","V14","V16","V17","V26",
"V27","V29","V31","V34","V37")] #seleccionamos las preguntas
names(datos3)=c("Parlanchin", "Victimista", "Deprimido", "Reservado", "Relajado",
"Peleonero", "Tenso", "Entusiasta",  "Indulgente", "Asertivo",
"Frio", "Malhumorado", "Timido", "Calmado", "Grosero")#renombramos
#colSums(is.na(datos3))#Verificar si las variables tienen Na's
#library(GGally)
#X11()
#ggpairs(datos3)#Ver las relaciones y si es necesario escalar
library(factoextra)
R.CP_org=prcomp(datos3,  scale = FALSE) #obtenemos las componentes principales sin sacale
R.CP_est=prcomp(datos3, scale = TRUE) #obtenemos las componentes principales con sacale
R.CP_log=prcomp(log10(datos3), scale = FALSE)#obtenemos las componentes principales con log
#Nos apoyamos con la varianza que recuperamos para decidir
print(summary(R.CP_org), digits=3) #en 4 se acumulan 62.6% y en 5 67.9%
print(summary(R.CP_est), digits=3) #en 4 se acumula 62.21% y en 5 67.48%
print(summary(R.CP_log), digits=3) #en 4 se acumula 63.92% y en 5 65.58%
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
#Ahora para interpretar, hay que sacar correlaciones entre comp principles
#y las variables originales
#A mayor/menor valor en el comp pricipal hay mas "variables"
options(digits=2)
cor(cbind(R.CP_org$x[,1:4],(datos3)))
cor(cbind(R.CP_est$x[,1:4], (scale(datos3))))
cor(cbind(R.CP_log$x[,1:4], (log(datos3))))
plot1<-fviz_pca_var(R.CP_org,labelsize = 3,repel = TRUE,
col.var = "contrib") + theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
plot2<-fviz_pca_var(R.CP_est,labelsize = 3,repel = TRUE,
col.var = "contrib") + theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
plot3<-fviz_pca_var(R.CP_log,labelsize = 3,repel = TRUE,
col.var= "contrib")+ theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
grid.arrange(plot1,  plot3,  ncol=2)
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "varimax")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
grid.arrange(plot4,  plot5,  ncol=2)
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
#grid.arrange(plot4,  plot5,  ncol=2)
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
colnames(FE_org$loadings) <- c("FactorA", "FactorB",  "FactorC")
colnames(FE_est$loadings) <- c("FactorA", "FactorB",  "FactorC")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
colnames(FE_org$loadings) <- c("A", "B",  "C")
colnames(FE_est$loadings) <- c("A", "B",  "C")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
colnames(FE_org$loadings) <- c("A", "B",  "C")
colnames(FE_est$loadings) <- c("A", "B",  "C")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", cex=9)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", cex=9)
#par( mfrow= c(1,2) )
colnames(FE_org$loadings) <- c("A", "B",  "C")
colnames(FE_est$loadings) <- c("A", "B",  "C")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", cex=9)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", cex=9)
#par( mfrow= c(1,2) )
colnames(FE_org$loadings) <- c("A", "B",  "C")
colnames(FE_est$loadings) <- c("A", "B",  "C")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", cex=12)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", cex=12)
#par( mfrow= c(1,2) )
colnames(FE_org$loadings) <- c("A", "B",  "C")
colnames(FE_est$loadings) <- c("A", "B",  "C")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", cex=5)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", cex=5)
#par( mfrow= c(1,2) )
colnames(FE_org$loadings) <- c("A", "B",  "C")
colnames(FE_est$loadings) <- c("A", "B",  "C")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", cex=5, e.cex=5)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", cex=5, e.cex=5)
#par( mfrow= c(1,2) )
colnames(FE_org$loadings) <- c("A", "B",  "C")
colnames(FE_est$loadings) <- c("A", "B",  "C")
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", cex=5, e.cex=2)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", cex=5, e.cex=2)
#Limpieza
rm(list = ls(all.names = TRUE)) #ambiente
gc()  #memoria
# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
echo = FALSE,
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F
)
datos3  <- read.csv("Dat3Ex.csv") #Variables continuas sin escalar
datos3 <- datos3[,c("V1", "V2", "V4", "V6", "V9", "V12","V14","V16","V17","V26",
"V27","V29","V31","V34","V37")] #seleccionamos las preguntas
names(datos3)=c("Parlanchin", "Victimista", "Deprimido", "Reservado", "Relajado",
"Peleonero", "Tenso", "Entusiasta",  "Indulgente", "Asertivo",
"Frio", "Malhumorado", "Timido", "Calmado", "Grosero")#renombramos
#colSums(is.na(datos3))#Verificar si las variables tienen Na's
#library(GGally)
#X11()
#ggpairs(datos3)#Ver las relaciones y si es necesario escalar
library(factoextra)
R.CP_org=prcomp(datos3,  scale = FALSE) #obtenemos las componentes principales sin sacale
R.CP_est=prcomp(datos3, scale = TRUE) #obtenemos las componentes principales con sacale
R.CP_log=prcomp(log10(datos3), scale = FALSE)#obtenemos las componentes principales con log
#Nos apoyamos con la varianza que recuperamos para decidir
print(summary(R.CP_org), digits=3) #en 4 se acumulan 62.6% y en 5 67.9%
print(summary(R.CP_est), digits=3) #en 4 se acumula 62.21% y en 5 67.48%
print(summary(R.CP_log), digits=3) #en 4 se acumula 63.92% y en 5 65.58%
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
#Ahora para interpretar, hay que sacar correlaciones entre comp principles
#y las variables originales
#A mayor/menor valor en el comp pricipal hay mas "variables"
options(digits=2)
cor(cbind(R.CP_org$x[,1:4],(datos3)))
cor(cbind(R.CP_est$x[,1:4], (scale(datos3))))
cor(cbind(R.CP_log$x[,1:4], (log(datos3))))
plot1<-fviz_pca_var(R.CP_org,labelsize = 3,repel = TRUE,
col.var = "contrib") + theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
plot2<-fviz_pca_var(R.CP_est,labelsize = 3,repel = TRUE,
col.var = "contrib") + theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
plot3<-fviz_pca_var(R.CP_log,labelsize = 3,repel = TRUE,
col.var= "contrib")+ theme(text = element_text(size = 7),
axis.title = element_text(size = 7.5),
axis.text = element_text(size = 7.5))
grid.arrange(plot1,  plot3,  ncol=2)
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores
FE_org <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_est <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 3, rotate = "varimax")
FE_log <- fa(log10(datos3), cor= "cor",
covar = TRUE, nfactor = 3, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
#par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", cex=5, e.cex=2)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", cex=5, e.cex=2)
#par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
#par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", labelsize=7)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", labelsize=7)
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", labelsize=2)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", labelsize=2)
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", cex=0.5)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", gap.size=0.5)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", e.cex=0.5)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", e.cex=1.5)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", rsize=0.15)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", e.size=.05,rsize=.15)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", e.size=.05,rsize=.15)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", e.size=.05,rsize=.15)
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala", e.size=.01,rsize=.15)
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados", e.size=.01,rsize=.15)
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
par( mfrow= c(1,2) )
plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
2. Para los datos estandarizados, las variables Deprimido, Tenso, Malhumorado, Grosero, Victimista, Peleonero y Frío son las que tienen mayor asociación positiva en el componente 1, y por otro lado Relajado, Calmado y Entusiasta son las que tienen mayor asociación negativa con el componente 1. Las variables Parlanchin y Asertivo son las de mayor asociación positiva para el componente 2, y Tímido y Reservado son las de mayor asociación negativa para el componente 2. Para el componente 3 las de mayor relación  positiva son Relajado, Frío y Calmado, mientras que para la relación negativa  con el componente 3 no hay valores mayores a 0.5 en valor absoluto. Y para el componente 4 la única variable con asociación negativa importante es indulgente, y todas las demás asociaciones son negativas menores a 0.5 en valor absoluto.
#2. Para los datos estandarizados, las variables Deprimido, Tenso, Malhumorado, Grosero, Victimista, Peleonero y Frío son las que tienen mayor asociación positiva en el componente 1, y por otro lado Relajado, Calmado y Entusiasta son las que tienen mayor asociación negativa con el componente 1. Las variables Parlanchin y Asertivo son las de mayor asociación positiva para el componente 2, y Tímido y Reservado son las de mayor asociación negativa para el componente 2. Para el componente 3 las de mayor relación  positiva son Relajado, Frío y Calmado, mientras que para la relación negativa  con el componente 3 no hay valores mayores a 0.5 en valor absoluto. Y para el componente 4 la única variable con asociación negativa importante es indulgente, y todas las demás asociaciones son negativas menores a 0.5 en valor absoluto.
#3. Para los datos en escala logarítmica, las variables Grosero, Deprimido, Frio, Peleonero, Tenso, Malhumorado y Victimista son las que tienen mayor asociación positiva en el componente 1, y por otro lado Relajado es la que tienen mayor asociación negativa con el componente 1. Las variables Parlanchin, Asertivo y Entusiasta son las de mayor asociación positiva para el componente 2, y Tímido y Reservado son las de mayor asociación negativa para el componente 2. Para el componente 3 la de mayor relación  positiva es Relajado mientras que para la relación negativa  con el componente 3 es Tímido. Y para el componente 4 no hay valores mayores a 0.5 en valor absoluto.
