rm(list = ls(all.names = TRUE))
gc()
# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
echo = FALSE,
fig.align = "center",
fig.dim = c(4.0, 3.0),
fig.pos = "htbp",
message = FALSE,
warning = FALSE,
error = F
)
set.seed(921) #No. de cuenta que termina en 921
library(ggplot2)
# Generación de muestras para el estimador de tau, se almacena en un solo dataframe.
mc_tau = c()
for (i in 1:10000){
mc_tau_i = (24/25)^(sum(rpois(25, lambda = 1.5)))
mc_tau = c(mc_tau, mc_tau_i)
}
mc_tau_df = data.frame(mc_tau)
mc_tau_df$sq_mc_tau_df = mc_tau_df$mc_tau^2
# Esperanza y varianza. Obtenemos la esperanza de acuerdo a la fórmula proporcionada.
mc_expec_tau = sum(mc_tau)/10000
mc_var_tau = sum(mc_tau_df$sq_mc_tau_df)/10000 - mc_expec_tau^2
print(max(mc_tau))
print(mc_expec_tau)
print(mc_var_tau)
# Histograma para tau obtenido por el método de Monte Carlo.
ggplot(mc_tau_df, aes(x = mc_tau)) +
geom_histogram(color = 'black', fill = '#27C907', aes(y = (..count..)/sum(..count..)), bins = 30) +
labs(
title = 'Distribución de las muestras generadas',
x = expression(widehat(tau)),
y = 'Porcentaje',
) +
scale_x_continuous(breaks = seq(0, max(mc_tau), 0.04)) +
scale_y_continuous(labels = scales::percent) +
theme_bw() +
theme(axis.text.x = element_text(size = 8))
# Generación de muestras Poisson y almacenado en un dataframe.
b_tau = rpois(25, lambda = 1.5)
b_tau_df = data.frame(b_tau)
View(b_tau_df)
# Definimos una función para obtener el parámetro buscado.
estadistica_tau = function(data, index){
new_data = data[c(index)]
tau_param = (24/25)^(sum(new_data))
return(tau_param)
}
# Bootstrap con lo definido previamente.
bstrap = boot::boot(data = b_tau, R = 10000, statistic = estadistica_tau)
print(bstrap$t0)
print(var(bstrap$t))
# Dataframe auxiliar para la gráfica.
b_tau_g_df = data.frame(bstrap$t)
# Histograma para tau de bootstrap.
ggplot(b_tau_g_df, aes(x = bstrap.t)) +
geom_histogram(color = 'black', fill = '#880808', aes(y = (..count..)/sum(..count..)), bins = 30) +
labs(
title = 'Distribución de las muestras generadas',
x = expression(widehat(tau)),
y = 'Porcentaje',
) +
scale_x_continuous(breaks = seq(0, max(b_tau_g_df), 0.04)) +
scale_y_continuous(labels = scales::percent) +
theme_bw() +
theme(axis.text.x = element_text(size = 8))
rm(list = ls(all.names = TRUE))
gc()
# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
echo = FALSE,
fig.align = "center",
#fig.dim = c(4.0, 3.0),
fig.pos = "htbp",
message = FALSE,
warning = FALSE,
error = F
)
# Generación de muestras Poisson y almacenado en un dataframe.
b_tau = rpois(20, lambda = 1)
b_tau_df = data.frame(b_tau)
View(b_tau_df)
# Definimos una función para obtener el parámetro buscado.
estadistica_tau = function(data, index){
new_data = data[c(index)]
tau_param = (19/20)^(sum(new_data))
return(tau_param)
}
# Bootstrap con lo definido previamente.
bstrap = boot::boot(data = b_tau, R = 10000, statistic = estadistica_tau)
print(bstrap$t0)
print(var(bstrap$t))
# Dataframe auxiliar para la gráfica.
b_tau_g_df = data.frame(bstrap$t)
bstrap$t0
var(bstrap$t
var(bstrap$t)
# Generación de muestras Poisson y almacenado en un dataframe.
b_tau = rpois(20, lambda = 1)
b_tau_df = data.frame(b_tau)
View(b_tau_df)
# Definimos una función para obtener el parámetro buscado.
estadistica_tau = function(data, index){
new_data = data[c(index)]
tau_param = (19/20)^(sum(new_data))
return(tau_param)
}
# Bootstrap con lo definido previamente.
bstrap = boot::boot(data = b_tau, R = 10000, statistic = estadistica_tau)
print(bstrap$t0)
print(var(bstrap$t))
# Dataframe auxiliar para la gráfica.
b_tau_g_df = data.frame(bstrap$t)
# Generación de muestras Poisson y almacenado en un dataframe.
b_tau = rpois(20, lambda = 1)
b_tau_df = data.frame(b_tau)
View(b_tau_df)
# Definimos una función para obtener el parámetro buscado.
estadistica_tau = function(data, index){
new_data = data[c(index)]
tau_param = (19/20)^(sum(new_data))
return(tau_param)
}
# Bootstrap con lo definido previamente.
bstrap = boot::boot(data = b_tau, R = 10000, statistic = estadistica_tau)
bstrapt0<-bstrap$t0
print(bstrapt0)
varbstrapt<-var(bstrap$t)
print(varbstrapt)
# Dataframe auxiliar para la gráfica.
b_tau_g_df = data.frame(bstrap$t)
# Generación de muestras Poisson y almacenado en un dataframe.
b_tau = rpois(20, lambda = 1)
b_tau_df = data.frame(b_tau)
View(b_tau_df)
# Definimos una función para obtener el parámetro buscado.
estadistica_tau = function(data, index){
new_data = data[c(index)]
tau_param = (19/20)^(sum(new_data))
return(tau_param)
}
# Bootstrap con lo definido previamente.
bstrap = boot::boot(data = b_tau, R = 10000, statistic = estadistica_tau)
bstrapt0<-bstrap$t0
print(bstrapt0)
varbstrapt<-var(bstrap$t)
print(varbstrapt)
# Dataframe auxiliar para la gráfica.
b_tau_g_df = data.frame(bstrap$t)
# Generación de muestras Poisson y almacenado en un dataframe.
b_tau = rpois(20, lambda = 1)
b_tau_df = data.frame(b_tau)
#View(b_tau_df)
# Definimos una función para obtener el parámetro buscado.
estadistica_tau = function(data, index){
new_data = data[c(index)]
tau_param = (19/20)^(sum(new_data))
return(tau_param)
}
# Bootstrap con lo definido previamente.
bstrap = boot::boot(data = b_tau, R = 10000, statistic = estadistica_tau)
bstrapt0<-bstrap$t0
print(bstrapt0)
varbstrapt<-var(bstrap$t)
print(varbstrapt)
# Dataframe auxiliar para la gráfica.
b_tau_g_df = data.frame(bstrap$t)
dif_e<-mc_expec_tau-bstrapt0
rm(list = ls(all.names = TRUE))
gc()
# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
echo = FALSE,
fig.align = "center",
#fig.dim = c(4.0, 3.0),
fig.pos = "htbp",
message = FALSE,
warning = FALSE,
error = F
)
set.seed(340) #No. de cuenta que termina en 340
library(ggplot2)
# Generación de muestras para el estimador de tau, se almacena en un solo dataframe.
mc_tau = c()
for (i in 1:10000){
mc_tau_i = (19/20)^(sum(rpois(20, lambda = 1)))
mc_tau = c(mc_tau, mc_tau_i)
}
mc_tau_df = data.frame(mc_tau)
mc_tau_df$sq_mc_tau_df = mc_tau_df$mc_tau^2
# Esperanza y varianza. Obtenemos la esperanza de acuerdo a la fórmula proporcionada.
mc_expec_tau = sum(mc_tau)/10000
mc_var_tau = sum(mc_tau_df$sq_mc_tau_df)/10000 - mc_expec_tau^2
print(max(mc_tau))
print(mc_expec_tau)
print(mc_var_tau)
# Histograma para tau obtenido por el método de Monte Carlo.
ggplot(mc_tau_df, aes(x = mc_tau)) +
geom_histogram(color = 'black', fill = 'blue', aes(y = (..count..)/sum(..count..)), bins = 30) +
labs(
title = ' ',
x = expression(widehat(tau)),
y = 'Frecuencia relativa',
) +
scale_x_continuous(breaks = seq(0, max(mc_tau), 0.04)) +
scale_y_continuous(labels = scales::percent) +
theme_bw() +
theme(axis.text.x = element_text(size = 8))
# Generación de muestras Poisson y almacenado en un dataframe.
b_tau = rpois(20, lambda = 1)
b_tau_df = data.frame(b_tau)
#View(b_tau_df)
# Definimos una función para obtener el parámetro buscado.
estadistica_tau = function(data, index){
new_data = data[c(index)]
tau_param = (19/20)^(sum(new_data))
return(tau_param)
}
# Bootstrap con lo definido previamente.
bstrap = boot::boot(data = b_tau, R = 10000, statistic = estadistica_tau)
bstrapt0<-bstrap$t0
print(bstrapt0)
varbstrapt<-var(bstrap$t)
print(varbstrapt)
# Dataframe auxiliar para la gráfica.
b_tau_g_df = data.frame(bstrap$t)
# Histograma para tau de bootstrap.
ggplot(b_tau_g_df, aes(x = bstrap.t)) +
geom_histogram(color = 'black', fill = '#880808', aes(y = (..count..)/sum(..count..)), bins = 30) +
labs(
title = ' ',
x = expression(widehat(tau)),
y = 'Porcentaje',
) +
scale_x_continuous(breaks = seq(0, max(b_tau_g_df), 0.04)) +
scale_y_continuous(labels = scales::percent) +
theme_bw() +
theme(axis.text.x = element_text(size = 8))
dif_e<-mc_expec_tau-bstrapt0
dif_v<-mc_var_tau-varbstrapt
dif_e<-round(mc_expec_tau-bstrapt0, digits = 7)
dif_v<-mc_var_tau-varbstrapt
dif_e<-round(mc_expec_tau-bstrapt0, digits = 7)
dif_v<-round(mc_var_tau-varbstrapt, digits = 7)
dif_e<-round(mc_expec_tau-bstrapt0, digits = 6)
dif_v<-round(mc_var_tau-varbstrapt, digits = 6)
dif_e<-round(mc_expec_tau-bstrapt0, digits = 6)
dif_v<-round(mc_var_tau-varbstrapt, digits = 6)
print(dif_v)
dif_e<-round(mc_expec_tau-bstrapt0, digits = 6)
dif_v<-round(mc_var_tau-varbstrapt, digits = 6)
print(dif_v[1])
dif_e<-round(mc_expec_tau-bstrapt0, digits = 6)
dif_v<-round(mc_var_tau-varbstrapt, digits = 6)
dif_vv<-dif_v[1]
#Limpieza
rm(list = ls(all.names = TRUE)) #ambiente
gc()  #memoria
# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
echo = FALSE,
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F
)
setwd("~/Seminario Estadistica/Tarea/")
#Limpieza
rm(list = ls(all.names = TRUE)) #ambiente
gc()  #memoria
# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
echo = FALSE,
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F
)
#setwd("~/Seminario Estadistica/Tarea/")
datos3  <- read.csv("Dat3Ex.csv") #Continuas sin escalar
datos3 <- datos3[,c("V1", "V2", "V3", "V6", "V8", "V12","V13","V16","V17","V26","V27","V28","V31","V33","V37")]
names(datos3)=c("Parlanchin", "Victimista", "Exhaustivo", "Reservado", "Descuidado",  "Peleonero", "Confiable",
"Entusiasta",  "Indulgente", "Asertivo", "Frio", "Perseverante", "Timido", "Eficiente", "Rudo")
#colSums(is.na(datos3))#No trae NA :p
#library(GGally)
#X11()
#ggpairs(datos3)   #Checamos el ggpairs para ver si es necesario escalar, pero como igual probraremos ambas lo dejamos comentado
library(factoextra)
R.CP_org=prcomp(datos3,  scale = FALSE)  #obtenemos las componentes principales
R.CP_est=prcomp(datos3, scale = TRUE)
R.CP_log=prcomp(log10(datos3), scale = FALSE)
#Nos apoyamos con la varianza que recuperamos para decidir
print(summary(R.CP_org), digits=3) #en 4 se acumulan 61% y en 5 66%
print(summary(R.CP_est), digits=3) #en 4 se acumula 60% y en 5 66%
print(summary(R.CP_log), digits=3) #en 4 se acumula 63% y en 5 69%
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar")
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados")
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica")
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
#Ahora para interpretar, hay que sacar correlaciones entre comp principles
#y las variables originales
#A mayor/menor valor en el comp pricipal hay mas "variables"
options(digits=2)
cor(cbind(R.CP_org$x[,1:4],(datos3)))
cor(cbind(R.CP_est$x[,1:4], (scale(datos3))))
cor(cbind(R.CP_log$x[,1:4], (log(datos3))))
plot1<-fviz_pca_var(R.CP_org,
col.var = "contrib")
plot3<-fviz_pca_var(R.CP_log,
col.var= "contrib")
grid.arrange(plot1, plot3,  ncol=2)
library(psych)
set.seed(123)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 4 factores
FE_org <- fa(datos3, cor= "cov",
covar = TRUE, nfactor = 4, rotate = "none")
FE_est <- fa(datos3, cor= "cor",
covar = TRUE, nfactor = 4, rotate = "none")
FE_log <- fa(log10(datos3), cor= "cov",
covar = TRUE, nfactor = 4, rotate = "none")
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186
FE_org$communalities #¿Qué tan bien explican cada variable?
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")
PC_org <-principal(datos3, cor="cov",
covar = TRUE, nfactor = 4, rotate = "none")
PC_Esc <-principal(datos3, cor="cor",
covar = TRUE, nfactor = 4, rotate = "none")
print(PC_org, cut = .5) #Acumula 61 y explica las variables en este orden: 0.42 0.27 0.19 0.13
print(PC_Esc, cut = .5) #Acumula 60 y explica en:  0.42 0.25 0.20 0.12
PC_org_varimax <-principal(datos3, cor="cov",
covar = TRUE, nfactor = 4, rotate = "varimax")
PC_Esc_varimax <-principal(datos3, cor="cor",
covar = TRUE, nfactor = 4, rotate = "varimax")
print(PC_org_varimax, cut = .5) #Acumula 61 y explica en: 0.33 0.30 0.22 0.14
print(PC_Esc_varimax, cut = .5) #Acumula 60 y explica en: 0.33 0.30 0.22 0.14
PC_org_oblimin <-principal(datos3, cor="cov",
covar = TRUE, nfactor = 4, rotate = "oblimin")
PC_Esc_oblimin <-principal(datos3, cor="cor",
covar = TRUE, nfactor = 4, rotate = "oblimin")
print(PC_org_oblimin, cut = .5) #Acumula 61 y explica en: 0.42 0.27 0.19 0.13
print(PC_Esc_oblimin, cut = .5) #Acumula 60 y explica en: 0.42 0.25 0.20 0.12
PC_org_cluster <-principal(datos3, cor="cov",
covar = TRUE, nfactor = 4, rotate = "cluster")
PC_Esc_cluster <-principal(datos3, cor="cor",
covar = TRUE, nfactor = 4, rotate = "cluster")
print(PC_org_cluster, cut = .5) #Acumula 61 y explica en: 0.33 0.30 0.20 0.17
print(PC_Esc_cluster, cut = .5) #Acumula 60 y explica en: 0.31 0.29 0.27 0.13
FA_org_varimax <-fa(datos3, cor="cov",
covar = TRUE, nfactor = 4, rotate = "varimax")
FA_Esc_varimax <-fa(datos3, cor="cor",
covar = TRUE, nfactor = 4, rotate = "varimax")
print(FA_org_varimax, cut = .5) #Acumula 46
print(FA_Esc_varimax, cut = .5) #Acumula 46
FA_org_oblimin <-fa(datos3, cor="cov",
covar = TRUE, nfactor = 4, rotate = "oblimin")
FA_Esc_oblimin <-fa(datos3, cor="cor",
covar = TRUE, nfactor = 4, rotate = "oblimin")
print(FA_org_oblimin, cut = .5) #Ambos acumulan 46
print(FA_Esc_oblimin, cut = .5)
FA_org_simplimax <-fa(datos3, cor="cov",
covar = TRUE, nfactor = 4, rotate = "simplimax")
FA_Esc_simplimax <-fa(datos3, cor="cor",
covar = TRUE, nfactor = 4, rotate = "simplimax")
print(FA_org_simplimax, cut = .5) #Acumulan 46
print(FA_Esc_simplimax, cut = .5) #Acumulan 46
CP_ord_varimax <- principal(datos3, cor="mixed",
covar = TRUE, nfactor = 4, rotate = "varimax")
CP_ord_cluster <- principal(datos3, cor="mixed",
covar = TRUE, nfactor = 4, rotate = "cluster")
FA_ord_oblimin <- fa(datos3, cor="mixed",
covar = TRUE, nfactor = 4, rotate = "oblimin")
FA_ord_simplimax <- fa(datos3, cor="mixed",
covar = TRUE, nfactor = 4, rotate = "simplimax")
print(CP_ord_varimax, cut=0.5) #Acumula 66 y explica 0.32 0.28 0.28 0.12
print(CP_ord_cluster, cut =0.5) #Acumula 66 y explica en:  0.31 0.29 0.27 0.13
print(FA_ord_oblimin, cut=.5)
print(FA_ord_simplimax, cut=.5)
fa.diagram(CP_ord_cluster, cut = .5, digits = 2)
#Limpieza
rm(list = ls(all.names = TRUE)) #ambiente
gc()  #memoria
# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
echo = FALSE,
fig.pos = "H",
message = FALSE,
warning = FALSE,
error = F
)
datos3  <- read.csv("Dat3Ex.csv")
View(datos3)
datos3 <- datos3[,c("V1", "V2", "V4", "V6", "V9", "V12","V14","V16","V17","V26",
"V27","V29","V31","V34","V37")] #seleccionamos las preguntas
names(datos3)=c("Parlanchin", "Victimista", "Deprimido", "Reservado", "Relajado",
"Peleonero", "Entusiasta", "Entusiasta",  "Indulgente", "Asertivo",
"Frio", "Malhumorado", "Timido", "Calmado", "Grosero")#renombramos
View(datos3)
colSums(is.na(datos3))
library(GGally)
X11()
ggpairs(datos3)   #Ver si es necesario escalar
datos3  <- read.csv("Dat3Ex.csv") #Variables continuas sin escalar
datos3 <- datos3[,c("V1", "V2", "V4", "V6", "V9", "V12","V14","V16","V17","V26",
"V27","V29","V31","V34","V37")] #seleccionamos las preguntas
names(datos3)=c("Parlanchin", "Victimista", "Deprimido", "Reservado", "Relajado",
"Peleonero", "Entusiasta", "Entusiasta",  "Indulgente", "Asertivo",
"Frio", "Malhumorado", "Timido", "Calmado", "Grosero")#renombramos
library(GGally)
X11()
ggpairs(datos3)   #Ver si es necesario escalar
datos3  <- read.csv("Dat3Ex.csv") #Variables continuas sin escalar
datos3 <- datos3[,c("V1", "V2", "V4", "V6", "V9", "V12","V14","V16","V17","V26",
"V27","V29","V31","V34","V37")] #seleccionamos las preguntas
names(datos3)=c("Parlanchin", "Victimista", "Deprimido", "Reservado", "Relajado",
"Peleonero", "Tenso", "Entusiasta",  "Indulgente", "Asertivo",
"Frio", "Malhumorado", "Timido", "Calmado", "Grosero")#renombramos
library(GGally)
X11()
ggpairs(datos3)   #Ver si es necesario escalar
library(GGally)
#X11()
ggpairs(datos3)   #Ver si es necesario escalar
library(factoextra)
R.CP_org=prcomp(datos3,  scale = FALSE) #obtenemos las componentes principales sin sacale
R.CP_est=prcomp(datos3, scale = TRUE) #obtenemos las componentes principales con sacale
R.CP_log=prcomp(log10(datos3), scale = FALSE)#obtenemos las componentes principales con log
#Nos apoyamos con la varianza que recuperamos para decidir
print(summary(R.CP_org), digits=3) #en 4 se acumulan 61% y en 5 66%
print(summary(R.CP_est), digits=3) #en 4 se acumula 60% y en 5 66%
print(summary(R.CP_log), digits=3) #en 4 se acumula 63% y en 5 69%
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar")
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados")
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica")
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance")
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance")
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance")
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="eigenvalue")
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="eigenvalue")
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="eigenvalue")
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance")
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance")
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance")
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE)
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE)
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE)
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE, hjust = 90)
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE, hjust = 90)
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE, hjust = 90)
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE, hjust = 0)
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE, hjust = 0)
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE, hjust = 0)
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE, hjust = 1)
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE, hjust = 1)
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE, hjust = 1)
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE, hjust = 1)
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE, hjust = 1)
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE, vjust = 1)
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE)
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE)
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE)
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
#Ahora para interpretar, hay que sacar correlaciones entre comp principles
#y las variables originales
#A mayor/menor valor en el comp pricipal hay mas "variables"
options(digits=2)
cor(cbind(R.CP_org$x[,1:4],(datos3)))
cor(cbind(R.CP_est$x[,1:4], (scale(datos3))))
cor(cbind(R.CP_log$x[,1:4], (log(datos3))))
#Ahora para interpretar, hay que sacar correlaciones entre comp principles
#y las variables originales
#A mayor/menor valor en el comp pricipal hay mas "variables"
options(digits=2)
cor(cbind(R.CP_org$x[,1:4],(datos3)))
cor(cbind(R.CP_est$x[,1:4], (scale(datos3))))
cor(cbind(R.CP_log$x[,1:4], (log(datos3))))
