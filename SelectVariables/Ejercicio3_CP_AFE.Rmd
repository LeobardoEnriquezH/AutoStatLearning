---
output:
  pdf_document:
    toc: no
  bookdown::pdf_document2:
    number_sections: no
    toc: no
    highlight: tango
table.placement: !ht
geometry: margin=2.0cm
header-includes:
- \usepackage[spanish]{babel}
- \usepackage[utf8]{inputenc}
- \decimalpoint
- \usepackage{float}
urlcolor: blue
---

\section{3. Componentes principales y análisis factorial exploratorio}

Se analiza la personalidad de  de 228 estudiates de una universidad de los Estados Unidos a partir de una encuesta resumida en ``Dat3Ex.csv``. Las respuestas de 1 "muy en desacuerdo", 2  "un poco en desacuerdo", 3  "ni de acuerdo ni en desacuerdo", 4  "un poco de acuerdo" y  5  "muy de acuerdo", para un grupo de 44 preguntas, de las cuales tomaremos 15: $V1, V2, V4, V6, V9, V12, V14, V16, V17, V26, V27, V29, V31, V34, V37$ (para mayor detalle ver el cuestionario). Los objetivos son los de obtener los componentes principales y hacer un análisis exploratorio factorial, para identificar dimensiones interesantes de los datos en su escala original y transformada. 



```{r setup, include=FALSE}
#Limpieza
rm(list = ls(all.names = TRUE)) #ambiente
gc()  #memoria

# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
	echo = FALSE,
	fig.pos = "H",
	message = FALSE,
	warning = FALSE,
	error = F
)
```


```{r datos3, include=FALSE}
datos3  <- read.csv("Dat3Ex.csv") #Variables continuas sin escalar 
datos3 <- datos3[,c("V1", "V2", "V4", "V6", "V9", "V12","V14","V16","V17","V26",
                    "V27","V29","V31","V34","V37")] #seleccionamos las preguntas
names(datos3)=c("Parlanchin", "Victimista", "Deprimido", "Reservado", "Relajado",  
                "Peleonero", "Tenso", "Entusiasta",  "Indulgente", "Asertivo", 
                "Frio", "Malhumorado", "Timido", "Calmado", "Grosero")#renombramos
```

```{r, echo=FALSE}
#colSums(is.na(datos3))#Verificar si las variables tienen Na's
```

```{r, echo=FALSE}
#library(GGally)
#X11()
#ggpairs(datos3)#Ver las relaciones y si es necesario escalar
```

Con la ayuda de la librería ``factoextra`` se obtuvieron los $Componentes\hspace{.2cm}Principales$ con la función ``prcomp`` (ver Chunk factorCP en la línea 64). 

```{r factorCP, include=FALSE}
library(factoextra)
R.CP_org=prcomp(datos3,  scale = FALSE) #obtenemos las componentes principales sin sacale 
R.CP_est=prcomp(datos3, scale = TRUE) #obtenemos las componentes principales con sacale  
R.CP_log=prcomp(log10(datos3), scale = FALSE)#obtenemos las componentes principales con log

#Nos apoyamos con la varianza que recuperamos para decidir 
print(summary(R.CP_org), digits=3) #en 4 se acumulan 62.6% y en 5 67.9%
print(summary(R.CP_est), digits=3) #en 4 se acumula 62.21% y en 5 67.48%
print(summary(R.CP_log), digits=3) #en 4 se acumula 63.92% y en 5 65.58%
```

Posteriormente se usa la función ``fviz_eig``  para el número de componentes a considerar según varianzas y en la siguiente Figura se muestran para los datos escalados y no escalados, se suguieren entre 4 o 5 componentes  pues después de estos ya no hay mucho cambio en la varianza que aportan. Además se acumula en los tres casos un aproximado de 62% a 63% de la varianza total cuando consideramos 4 componentes (Chunk Grafica13, linea 79).   


```{r Grafica13, fig.dim=c(7.0, 3.5),	fig.align = "center" ,fig.cap= "Índices para número de componentes principales", include=TRUE}
library(gridExtra)
plot_org <- fviz_eig(R.CP_org, main = "Sin escalar", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
plot_est <- fviz_eig(R.CP_est, main = "Estandarizados", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
plot_log <- fviz_eig(R.CP_log, main = "Logaritmica", choice ="variance", addlabels = TRUE, labelsize = 3,repel = TRUE)+theme(text = element_text(size = 9))
grid.arrange(plot_org, plot_est, plot_log, ncol = 3)
```

```{r Correlation, include=FALSE}
#Ahora para interpretar, hay que sacar correlaciones entre comp principles
#y las variables originales 
#A mayor/menor valor en el comp pricipal hay mas "variables" 
options(digits=2)
cor(cbind(R.CP_org$x[,1:4],(datos3)))  
cor(cbind(R.CP_est$x[,1:4], (scale(datos3))))
cor(cbind(R.CP_log$x[,1:4], (log(datos3))))
```

Analizamos las correlaciones de las primeras cuatro componentes con las variables originales (Chunk Correlation, linea 87). Se describen los siguientes resultados generales, considerando correlaciones mayores a 0.5 en valor absoluto, para dar una mayor comprensión y contexto de las variables y componentes principales. La siguiente descripción solamente se presenta para los valores originales, también se hace el ejercicio para datos estandarizados y en logaritmos, sin embargo los resultados son similares por lo que no se describen.   


Para los datos sin escalar, las variables Deprimido, Tenso, Malhumorado y Grosero son las que tienen mayor asociación positiva en el componente 1, y por otro lado Relajado, Calmado y Entusiasta son las que tienen mayor asociación negativa con el componente 1. Las variables Parlanchin, Asertivo y Entusiasta son las de mayor asociación positiva para el componente 2, y Tímido y Reservado son las de mayor asociación negativa para el componente 2. Para el componente 3 las de mayor relación  positiva son Relajado, Frío y Calmado, mientras que para la relación negativa  con el componente 3 no hay valores mayores a 0.5 en valor absoluto. Y para el componente 4 no hay valores mayores a 0.5 en valor absoluto (sin embargo, mencionaremos que las de mayor relación positiva son Tímido, Indulgente y Entusiasta, mientras que las únicas con relación negativa son Frío, Peleonero y Victimista). 


```{r, echo=FALSE, include=FALSE}
#2. Para los datos estandarizados, las variables Deprimido, Tenso, Malhumorado, Grosero, Victimista, Peleonero y Frío son las que tienen mayor asociación positiva en el componente 1, y por otro lado Relajado, Calmado y Entusiasta son las que tienen mayor asociación negativa con el componente 1. Las variables Parlanchin y Asertivo son las de mayor asociación positiva para el componente 2, y Tímido y Reservado son las de mayor asociación negativa para el componente 2. Para el componente 3 las de mayor relación  positiva son Relajado, Frío y Calmado, mientras que para la relación negativa  con el componente 3 no hay valores mayores a 0.5 en valor absoluto. Y para el componente 4 la única variable con asociación negativa importante es indulgente, y todas las demás asociaciones son negativas menores a 0.5 en valor absoluto.  

#3. Para los datos en escala logarítmica, las variables Grosero, Deprimido, Frio, Peleonero, Tenso, Malhumorado y Victimista son las que tienen mayor asociación positiva en el componente 1, y por otro lado Relajado es la que tienen mayor asociación negativa con el componente 1. Las variables Parlanchin, Asertivo y Entusiasta son las de mayor asociación positiva para el componente 2, y Tímido y Reservado son las de mayor asociación negativa para el componente 2. Para el componente 3 la de mayor relación  positiva es Relajado mientras que para la relación negativa  con el componente 3 es Tímido. Y para el componente 4 no hay valores mayores a 0.5 en valor absoluto. 
```





Para mayor interpretabilidad visual tenemos la siguiente Gráfica (Chunk Grafica23, línea 118), sólo se presentan los datos originales y los de escala logaritmica, las estandarizadas son iguales a las originales. Estas son las proyecciones de las variables de mayor peso en los primeros 2 componentes principales, rescatan la mayor varianza, podemos observar el sentido y magnitud de las fechas para visualizar la influencia de cada variables en cada componente. 


```{r Grafica23,fig.dim=c(9, 4), fig.align = "center", fig.cap= "Proyeccion en componentes (izquierda: escala original; derecha:escala log)" ,include=TRUE}
plot1<-fviz_pca_var(R.CP_org,labelsize = 3,repel = TRUE,
             col.var = "contrib") + theme(text = element_text(size = 7),
        axis.title = element_text(size = 7.5),
        axis.text = element_text(size = 7.5))

plot2<-fviz_pca_var(R.CP_est,labelsize = 3,repel = TRUE,
             col.var = "contrib") + theme(text = element_text(size = 7),
        axis.title = element_text(size = 7.5),
        axis.text = element_text(size = 7.5))

plot3<-fviz_pca_var(R.CP_log,labelsize = 3,repel = TRUE,
             col.var= "contrib")+ theme(text = element_text(size = 7),
        axis.title = element_text(size = 7.5),
        axis.text = element_text(size = 7.5))
grid.arrange(plot1,  plot3,  ncol=2)
```

Para continuar con el análisis consideramos el enfoque de $Análisis\hspace{.1cm}Factorial\hspace{0.1cm}Exploratorio$, para ello nos apoyamos de la librería ``pysch`` y la función ``fa``. De nuevo consideramos datos sin escalar y estandarizados, optamos por considerar 3 factores, en los 2 casos Indulgente no queda en ninguno (Chunk Factorial, linea 131).

```{r Factorial, include=FALSE}
library(psych)
set.seed(340)
parallel <- fa.parallel((datos3), fa="fa", n.iter=100) #Suguiere 3 factores 

FE_org <- fa(datos3, cor= "cor",
             covar = TRUE, nfactor = 3, rotate = "none")

FE_est <- fa(datos3, cor= "cov",
             covar = TRUE, nfactor = 3, rotate = "varimax")

FE_log <- fa(log10(datos3), cor= "cor",
             covar = TRUE, nfactor = 3, rotate = "none")
```

```{r Criterios, include=FALSE}
FE_org #Explica el 46%, no rechazamos H0 es buena idea usarlo, -192 BIC, RMSEA de 0.05 
FE_est #Explica el 46%, no rechazamos H0, RMSEA de  0.05  y BIC = -192
FE_log #Excplica el 41% no rechazamos H0, RMSEA de 0.05 , TuckerL = 0.99 y BIC= -186

FE_org$communalities #¿Qué tan bien explican cada variable?  
FE_est$communalities
FE_log$communalities #Este explica mejor individualmentes pero los otros en general
```


```{r Grafica33, include=TRUE, fig.width=7, fig.height=4}
par( mfrow= c(1,2) )

plot4<-fa.diagram(FE_org,cut = 0.4 , main = "Sin escala")
plot5<-fa.diagram(FE_est,cut = 0.4 , main = "Estandarizados")

```

De las gráficas anteriores podemos notar, 3 componentes parecen ser suficiente para resumir la información, en contraste con componentes principales hemos reducido un poco más la dimensionalidad, además los resultados son muy similares a los componentes principales pues las variables de mayor peso se repiten casi todos los casos. 


Para decidirnos por un modelo se probaron varias rotaciones como varimax y simplimax, también se consideraron a las variables como ordinales y de nuevo con ayuda de fa se obtuvieron las variables latentes mientras que con principal las componentes principales (ver Chunks RotacionesCP, RotacionesAFE y Ordinales; lineas 170, 203 y 228). Optamos por un modelo de Componente principales pues estos recuperan más varianza y dentro de estos el que usa la rotación "cluster" y maneja las variables como ordinales es el mejor rankeado pues recupera un 66% de varianza total, además nos restringimos a considerar sólo 3 componentes pues el cuarto sólo está relacionado con una variable (Indulgente).  


```{r RotacionesCP, include=FALSE}
PC_org <-principal(datos3, cor="cov",
                   covar = TRUE, nfactor = 4, rotate = "none")
PC_Esc <-principal(datos3, cor="cor",
                   covar = TRUE, nfactor = 4, rotate = "none")
print(PC_org, cut = .5) #Acumula 61 y explica las variables en este orden: 0.42 0.27 0.19 0.13
print(PC_Esc, cut = .5) #Acumula 60 y explica en:  0.42 0.25 0.20 0.12


PC_org_varimax <-principal(datos3, cor="cov",
                   covar = TRUE, nfactor = 4, rotate = "varimax")
PC_Esc_varimax <-principal(datos3, cor="cor",
                   covar = TRUE, nfactor = 4, rotate = "varimax")
print(PC_org_varimax, cut = .5) #Acumula 61 y explica en: 0.33 0.30 0.22 0.14
print(PC_Esc_varimax, cut = .5) #Acumula 60 y explica en: 0.33 0.30 0.22 0.14


PC_org_oblimin <-principal(datos3, cor="cov",
                   covar = TRUE, nfactor = 4, rotate = "oblimin")
PC_Esc_oblimin <-principal(datos3, cor="cor",
                   covar = TRUE, nfactor = 4, rotate = "oblimin")
print(PC_org_oblimin, cut = .5) #Acumula 61 y explica en: 0.42 0.27 0.19 0.13
print(PC_Esc_oblimin, cut = .5) #Acumula 60 y explica en: 0.42 0.25 0.20 0.12


PC_org_cluster <-principal(datos3, cor="cov",
                   covar = TRUE, nfactor = 4, rotate = "cluster")
PC_Esc_cluster <-principal(datos3, cor="cor",
                   covar = TRUE, nfactor = 4, rotate = "cluster")
print(PC_org_cluster, cut = .5) #Acumula 61 y explica en: 0.33 0.30 0.20 0.17
print(PC_Esc_cluster, cut = .5) #Acumula 60 y explica en: 0.31 0.29 0.27 0.13
```

```{r RotacionesAFE, include=FALSE}
FA_org_varimax <-fa(datos3, cor="cov",
                   covar = TRUE, nfactor = 4, rotate = "varimax")
FA_Esc_varimax <-fa(datos3, cor="cor",
                   covar = TRUE, nfactor = 4, rotate = "varimax")
print(FA_org_varimax, cut = .5) #Acumula 46
print(FA_Esc_varimax, cut = .5) #Acumula 46


FA_org_oblimin <-fa(datos3, cor="cov",
                   covar = TRUE, nfactor = 4, rotate = "oblimin")
FA_Esc_oblimin <-fa(datos3, cor="cor",
                   covar = TRUE, nfactor = 4, rotate = "oblimin")
print(FA_org_oblimin, cut = .5) #Ambos acumulan 46
print(FA_Esc_oblimin, cut = .5)


FA_org_simplimax <-fa(datos3, cor="cov",
                   covar = TRUE, nfactor = 4, rotate = "simplimax")
FA_Esc_simplimax <-fa(datos3, cor="cor",
                   covar = TRUE, nfactor = 4, rotate = "simplimax")
print(FA_org_simplimax, cut = .5) #Acumulan 46
print(FA_Esc_simplimax, cut = .5) #Acumulan 46
```

```{r Ordinales, include=FALSE}
CP_ord_varimax <- principal(datos3, cor="mixed",
                   covar = TRUE, nfactor = 4, rotate = "varimax")
CP_ord_cluster <- principal(datos3, cor="mixed",
                   covar = TRUE, nfactor = 4, rotate = "cluster")

FA_ord_oblimin <- fa(datos3, cor="mixed",
                   covar = TRUE, nfactor = 4, rotate = "oblimin")
FA_ord_simplimax <- fa(datos3, cor="mixed",
                   covar = TRUE, nfactor = 4, rotate = "simplimax")

print(CP_ord_varimax, cut=0.5) #Acumula 66 y explica 0.32 0.28 0.28 0.12
print(CP_ord_cluster, cut =0.5) #Acumula 66 y explica en:  0.31 0.29 0.27 0.13
print(FA_ord_oblimin, cut=.5)
print(FA_ord_simplimax, cut=.5)
```

```{r Grafica43, fig.cap="Componentes principales modelo seleccionado"}
fa.diagram(CP_ord_cluster, cut = .5, digits = 2)
```


Ya con nuestro modelo seleccionado pasamos a la interpretación, según las Gráfica anterior. El componente 1 corresponde a alumnos victimistas, fríos, groseros y peleoneros. En el componente 2,  tenemos alumnos para los que ser asertivo, parlanchín y entusiasta se tiene un mayor relación positiva con el componente y ser tímidos y reservados los mayores valores negativos.  Finalmente, en el componente 3 podemos notar mayores relaciones de alumnos deprimidos, malhumorados y tensos, mientras tenemos negativamente a alumnos calmados y relajados.  

